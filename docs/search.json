[
  {
    "objectID": "CoffeeRatings.html",
    "href": "CoffeeRatings.html",
    "title": "Coffee Ratings",
    "section": "",
    "text": "In this project I will be using data from Jo Hardin’s collection of “Tidy Tuesday” data sets.\n\nlibrary(tidyverse)\ndata &lt;- tidytuesdayR::tt_load('2020-07-07')\ncoffee_ratings &lt;- data[[\"coffee_ratings\"]]\n\nThe data Im using comes from the Coffee Quality Database posted by Buzzfeed Data Scientist James LeDoux. These data were collected from the Coffee Quality Institute’s review pages in January 2018.\n\ncoffee_ratings |&gt;\n  head(1)\n\n# A tibble: 1 × 43\n  total_cup_points species owner    country_of_origin farm_name lot_number mill \n             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;             &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;\n1             90.6 Arabica metad p… Ethiopia          metad plc &lt;NA&gt;       meta…\n# ℹ 36 more variables: ico_number &lt;chr&gt;, company &lt;chr&gt;, altitude &lt;chr&gt;,\n#   region &lt;chr&gt;, producer &lt;chr&gt;, number_of_bags &lt;dbl&gt;, bag_weight &lt;chr&gt;,\n#   in_country_partner &lt;chr&gt;, harvest_year &lt;chr&gt;, grading_date &lt;chr&gt;,\n#   owner_1 &lt;chr&gt;, variety &lt;chr&gt;, processing_method &lt;chr&gt;, aroma &lt;dbl&gt;,\n#   flavor &lt;dbl&gt;, aftertaste &lt;dbl&gt;, acidity &lt;dbl&gt;, body &lt;dbl&gt;, balance &lt;dbl&gt;,\n#   uniformity &lt;dbl&gt;, clean_cup &lt;dbl&gt;, sweetness &lt;dbl&gt;, cupper_points &lt;dbl&gt;,\n#   moisture &lt;dbl&gt;, category_one_defects &lt;dbl&gt;, quakers &lt;dbl&gt;, color &lt;chr&gt;, …\n\n\nThe variable I am using is ‘total_cup_points’ which is the Total rating/points of a specific coffee on a scale from 0-100.\n\nnew_coffee_ratings &lt;- coffee_ratings |&gt;\n  group_by(country_of_origin) |&gt;\n  filter(!is.na(country_of_origin)) |&gt;\n  summarise(avg_score = mean(total_cup_points, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_score))\n\nThis chunk takes the average “total_cup_points” for each country in the data set, and arranges those values in descending order. Now we can plot our findings using ggplot.\n\nggplot(new_coffee_ratings, aes(x = reorder(country_of_origin, avg_score), y = avg_score, fill = country_of_origin)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = 'Average \"Cup Points\" Score by Country of Origin',\n       x = \"Country of Origin\",\n       y = \"Average Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text = element_text(size = 7))\n\n\n\n\nAs we can see from the plot, Papa New Guinea has the highest Average Score in total cup points. We can also conclude that most total cup point scores are between 75 and 90, as all of the bars are relatively close in length."
  },
  {
    "objectID": "SimulatedSpotify.html#generate-listening-history",
    "href": "SimulatedSpotify.html#generate-listening-history",
    "title": "Simulated Spotify Wrapped",
    "section": "Generate Listening History",
    "text": "Generate Listening History\n\nwant to simulate a YEAR worth of listening history\n60,000 / 3.5 = 17,100\n\n\nmy_spotify_library &lt;- read.csv(\"~/paitynleigh.github.io/MyspotifyLibrary.csv\")\n\ncolnames(my_spotify_library)\n\n[1] \"Track.name\"    \"Artist.name\"   \"Album\"         \"Playlist.name\"\n[5] \"Type\"          \"ISRC\"          \"Spotify...id\" \n\n\n\n\nTool “Tune My Music” Used to collect playlist data https://www.tunemymusic.com/transfer"
  },
  {
    "objectID": "SimulatedSpotify.html#data-conclusions",
    "href": "SimulatedSpotify.html#data-conclusions",
    "title": "Simulated Spotify Wrapped",
    "section": "Data Conclusions",
    "text": "Data Conclusions\n\nRecreating Spotify Wrapped\nTop 5 Songs, Artists, and Albums\n\n\ntop_5 &lt;- function(data, colname){\n  data |&gt;\n    count({{colname}}, sort = TRUE)|&gt;\n    head(5)\n}\n\n\nCan use this same function for songs, artists, and albums"
  },
  {
    "objectID": "SimulatedSpotify.html#now-lets-see-1-iteration-of-simulated-listening-history",
    "href": "SimulatedSpotify.html#now-lets-see-1-iteration-of-simulated-listening-history",
    "title": "Simulated Spotify Wrapped",
    "section": "Now, Lets see 1 iteration of Simulated Listening History",
    "text": "Now, Lets see 1 iteration of Simulated Listening History\n\nfind_top_5 &lt;- function(simulated_year) {\n  top_songs &lt;- top_5(simulated_year, Track.name)\n  top_artists &lt;- top_5(simulated_year, Artist.name)\n  top_albums &lt;- top_5(simulated_year, Album)\n  \n  # labels each table \n  list(songs = top_songs, artists = top_artists, albums = top_albums)\n}\nfind_top_5(simulated_year(my_spotify_library))\n\n$songs\n         Track.name  n\n1            Nobody 33\n2              Hope 27\n3       Lay Me Down 26\n4               Why 25\n5 Come Away With Me 24\n\n$artists\n          Artist.name   n\n1              Mitski 478\n2        Lana Del Rey 269\n3 Panic! At The Disco 237\n4              Alex G 205\n5             TV Girl 193\n\n$albums\n                      Album   n\n1 Cry Baby (Deluxe Edition) 122\n2             Be the Cowboy 117\n3       Death of a Bachelor  92\n4        My Worlds Acoustic  80\n5                   MONTERO  78"
  },
  {
    "objectID": "SimulatedSpotify.html#mapping",
    "href": "SimulatedSpotify.html#mapping",
    "title": "Simulated Spotify Wrapped",
    "section": "Mapping",
    "text": "Mapping\n\nLets create multiple simulated years of listening\n\n\niters &lt;- 1000\n\nresults &lt;- map(1:iters, ~ {\n  simulated_year &lt;- simulated_year(my_spotify_library) \n  find_top_5(simulated_year) \n})\n\n\nWhat questions can mapping help us answer?"
  },
  {
    "objectID": "SimulatedSpotify.html#probability",
    "href": "SimulatedSpotify.html#probability",
    "title": "Simulated Spotify Wrapped",
    "section": "Probability",
    "text": "Probability\n\nHow likely is it that a specific artist will be in my top 5? Top 1??\n\n\ncheck_artist &lt;- function(top_artists, artist) {\n  in_top_5 &lt;- top_artists|&gt;\n    filter(Artist.name == artist) |&gt;\n    # Will return Boolean for this statement\n    nrow() &gt; 0  \n  \n  is_top_artist &lt;- top_artists |&gt;\n    pull(Artist.name) |&gt;\n    head(1) == artist \n  \n  list(\n    in_top_5 = in_top_5,\n    is_top_artist = is_top_artist\n  )\n}"
  },
  {
    "objectID": "SimulatedSpotify.html#cont.",
    "href": "SimulatedSpotify.html#cont.",
    "title": "Simulated Spotify Wrapped",
    "section": "cont.",
    "text": "cont.\n\nartist &lt;- \"TV Girl\"\n\nartist_occurrences &lt;- map(results, function(results) {\n\n  check_artist(pluck(results, \"artists\"), artist)\n})\n\ndata &lt;- map_dfr(artist_occurrences, ~ tibble(\n  in_top_5 = pluck(.x, \"in_top_5\"),\n  is_top_artist = pluck(.x, \"is_top_artist\")\n))\n\ndata|&gt;\n  head(1)\n\n# A tibble: 1 × 2\n  in_top_5 is_top_artist\n  &lt;lgl&gt;    &lt;lgl&gt;        \n1 FALSE    FALSE"
  },
  {
    "objectID": "SimulatedSpotify.html#conclusions",
    "href": "SimulatedSpotify.html#conclusions",
    "title": "Simulated Spotify Wrapped",
    "section": "Conclusions",
    "text": "Conclusions\n\nprob_top_5 &lt;- data |&gt;\n  select(in_top_5) |&gt;\n  summarise(mean = mean(in_top_5))|&gt;\n  pull(mean)\n\nprob_top_1 &lt;- data |&gt;\n  select(is_top_artist) |&gt;\n  summarise(mean = mean(is_top_artist))|&gt;\n  pull(mean)\n\nprob_top_5\n\n[1] 0.284\n\nprob_top_1\n\n[1] 0"
  },
  {
    "objectID": "Rodentdata.html",
    "href": "Rodentdata.html",
    "title": "Rodent Species",
    "section": "",
    "text": "In this project I will be using data from Jo Hardin’s collection of “Tidy Tuesday” data sets.\n\ndata &lt;- tidytuesdayR::tt_load('2023-05-02')\nspecies &lt;- data[[\"species\"]]\nlibrary(tidyverse)\n\nThe data I am using comes from the Portal Project.The Portal Project is a long-term ecological study being conducted near Portal, AZ. Since 1977, the site has been used to study the interactions among rodents, ants and plants and their respective responses to climate. This data pertains specifically to rodents.\n\nspecies |&gt;\n  head(1)\n\n# A tibble: 1 × 15\n  species scientificname  taxa   commonname     censustarget unidentified rodent\n  &lt;chr&gt;   &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 BA      Baiomys taylori Rodent Northern pygm…            1            0      1\n# ℹ 8 more variables: granivore &lt;dbl&gt;, minhfl &lt;dbl&gt;, meanhfl &lt;dbl&gt;,\n#   maxhfl &lt;dbl&gt;, minwgt &lt;dbl&gt;, meanwgt &lt;dbl&gt;, maxwgt &lt;dbl&gt;, juvwgt &lt;dbl&gt;\n\n\nThe variables I will be using are ‘meanwgt’ and ‘juvwgt’. These are the average adult weight and the average juvenile weight of a given species, respectively.\n\nweight_data &lt;- species |&gt;\n  mutate(weight_difference = meanwgt - juvwgt) |&gt;\n  filter(!is.na(weight_difference)) |&gt;\n  select(commonname, weight_difference)\n\nI wanted to find the average amount of growth a given rodent experiences in its lifetime so I subtracted the juvenile weight from the mean weight of the species. We then get a table with the species’ common name and the “weight_difference” or the growth amount in the species life.\n\nlibrary(ggplot2)\nggplot(weight_data, aes(x = reorder(commonname, weight_difference), y = weight_difference, fill = weight_difference)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + \n  scale_fill_gradient(low = \"pink\", high = \"orange\") +\n  labs(title = \"Average Lifetime Growth Across Rodent Species\",\n       x = \"Species Name\",\n       y = \"Growth Amount (g)\") +\n  theme_minimal()\n\n\n\n\nWe can conclude from the visual that the White-throated Woodrat experiences the largest amount of growth in its life. The growth amount measurement does not account for the size of the species meaning a better measurement for comparison would be the growth amount relative to the species average size."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Paityn Richardson",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "Project3.html",
    "href": "Project3.html",
    "title": "Poker Hands Probability",
    "section": "",
    "text": "In this project I plan to simulate the probability of being dealt a specific hand while playing poker. First I will simulate a deck of cards and then simulate the drawing of a 5 card hand with a function. Then I will use another function to check if the hand drawn at random matches a specific, special hand such as a full house, royal flush, etc.\nFirst, lets simulate a deck of cards\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(purrr)\n\n#use crossing function to associate each of the values with one of each of the suits \n\n\ndeck &lt;- crossing(value = c(2:10, \"J\", \"Q\", \"K\", \"A\"),\n\n                 suit = c(\"Spades\", \"Diamonds\", \"Clubs\", \"Hearts\"))\n\nNow, lets create a function that will deal a random hand of 5 cards from the deck.\n\ndeal_hand &lt;- function(deck){\n\n#pick random row numbers then index through deck data set to pick those specific rows \n\n  hand &lt;- deck[sample(nrow(deck), 5, replace = FALSE), ]\n\n  return(hand)\n\n}\n\ndeal_hand(deck)\n\n# A tibble: 5 × 2\n  value suit    \n  &lt;chr&gt; &lt;chr&gt;   \n1 9     Hearts  \n2 A     Diamonds\n3 A     Spades  \n4 8     Spades  \n5 K     Spades  \n\n\nNow, lets write a few functions that will check for special hands.\n\ncheck_straight &lt;- function(hand){\n\n  value_order &lt;- c(\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"J\", \"Q\", \"K\", \n\n\"A\")\n\n  ordered_hand_values &lt;- match(hand$value, value_order)\n  \n  is_straight &lt;- all(diff(sort(ordered_hand_values)) == 1)\n\n  return(is_straight)\n\n}\n\ncheck_royal_flush &lt;- function(hand){\n\n  royal_values &lt;- c(\"10\", \"J\", \"Q\", \"K\", \"A\")\n\n  \n\n  is_flush &lt;- if_else(length(unique(hand$suit)) == 1, TRUE, FALSE)\n\n  is_royal &lt;- if_else(all(royal_values %in% hand$value), TRUE, FALSE)\n\n  return(is_flush && is_royal)\n\n}\n\ncheck_full_house &lt;- function(hand){\n\n  value_frequency &lt;- table(hand$value)\n\n  \n\n  #Gives True if there exactly 2 unique values and there are 3 repeats of the first value and 2 repeats of the second\n\n    if_else(length(value_frequency) == 2 &\n\n            all(value_frequency == c(3,2)), TRUE, FALSE)\n\n}\n\nNow, say this is a specific night at a casino and we want to know the probability that someone will be dealt a full house or a royal flush. Lets map these functions over numerous iterations in order to model this.\n\nset.seed(738)\niterations &lt;- 100000\n\nresults &lt;- \n  tibble(full_house = mean(map_lgl(1:iterations, ~check_full_house(deal_hand(deck)))),\n        royal_flush = mean(map_lgl(1:iterations, ~check_royal_flush(deal_hand(deck)))),\n        straight = mean(map_lgl(1:iterations, ~check_straight(deal_hand(deck)))))\n\nresults &lt;- results|&gt;\n  pivot_longer(cols = everything(), names_to = \"hand\", values_to = \"probability\")\n\nNow lets plot these results using a bar plot.\n\nggplot(results, aes(x = hand, y = probability, fill = hand)) +\n\n  geom_bar(stat = \"identity\") +\n\n  labs(title = \"Probabilities of Different Poker Hands\",\n\n       x = \"Poker Hand\",\n\n       y = \"Probability\") +\n\n  theme_minimal()\n\n\n\n\nAs we can see on the bar plot, a straight is the most common out of all the hands followed a full house and then a royal flush. With this information we can start to understand how common it is to be dealt certain hands in poker. This can be useful when trying to curb cheating attempts and or trying to place bets. This could also be helpful when designing online poker games and attempting to accurately replicate a real life game."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "hahahahhahha im evil lollllllowoahfbu3iebfuwbeiw",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "WAIDatabaseStudy.html",
    "href": "WAIDatabaseStudy.html",
    "title": "WAI Database Study",
    "section": "",
    "text": "library(RMariaDB)\nlibrary(tidyverse)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\nIn this project I plan to use the data from the Wideband Acoustic Immittance (WAI) Database hosted by Smith College. I plan to replicate a figure published in the Official Journal of the American Auditory Society by Susan Voss titled “Mean Absorbance from each Publication in the WAI Database” Voss(2020). The database contains 3 data sets: Measurements, PI_Info, and Subjects, which all have different information pertaining to the study.\nHere is the measurements table,\n\nDESCRIBE Measurements\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSession\nint\nNO\nPRI\nNA\n\n\n\nEar\nvarchar(50)\nNO\nPRI\n\n\n\n\nInstrument\nvarchar(50)\nNO\nPRI\n\n\n\n\nAge\nfloat\nYES\n\nNA\n\n\n\nAgeCategory\nvarchar(50)\nYES\n\nNA\n\n\n\nEarStatus\nvarchar(50)\nYES\n\nNA\n\n\n\nTPP\nfloat\nYES\n\nNA\n\n\n\nAreaCanal\nfloat\nYES\n\nNA\n\n\n\n\n\n\nHere is the PI_Info table,\n\nDESCRIBE PI_Info\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nYear\nint\nNO\n\nNA\n\n\n\nAuthors\ntext\nNO\n\nNA\n\n\n\nAuthorsShortList\ntext\nNO\n\nNA\n\n\n\nTitle\ntext\nNO\n\nNA\n\n\n\nJournal\ntext\nNO\n\nNA\n\n\n\nURL\ntext\nNO\n\nNA\n\n\n\nAbstract\ntext\nNO\n\nNA\n\n\n\nDataSubmitterName\ntext\nNO\n\nNA\n\n\n\nDataSubmitterEmail\ntext\nNO\n\nNA\n\n\n\n\n\n\nAnd here is the Subjects table,\n\nDESCRIBE Subjects\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSessionTotal\nint\nNO\n\nNA\n\n\n\nAgeFirstMeasurement\nfloat\nYES\n\nNA\n\n\n\nAgeCategoryFirstMeasurement\nvarchar(50)\nYES\n\nNA\n\n\n\nSex\nvarchar(50)\nNO\n\nNA\n\n\n\nRace\nvarchar(50)\nNO\n\nNA\n\n\n\nEthnicity\nvarchar(50)\nNO\n\nNA\n\n\n\nLeftEarStatusFirstMeasurement\nvarchar(50)\nNO\n\nNA\n\n\n\nRightEarStatusFirstMeasurement\nvarchar(50)\nNO\n\nNA\n\n\n\n\n\n\nI started of by arranging the data using a SQL query.\n\n    SELECT \n        m.Frequency,\n        m.Identifier,\n        m.Instrument,\n        AVG(m.Absorbance) AS Mean_Absorption, \n        CONCAT(pi.AuthorsShortList, ' (', pi.Year, ')', ' N=', COUNT(DISTINCT CONCAT(m.SubjectNumber, '-', m.Ear)),'; ', m.Instrument) AS Label\n    FROM \n        Measurements m\n    JOIN \n        PI_Info pi\n        ON m.Identifier = pi.Identifier\n    WHERE \n        m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', 'Lewis_2015', 'Lui_2008', 'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', 'Voss_1994', 'Voss_2010', 'Werner_2010') \n        AND m.Frequency BETWEEN 200 AND 8000\n    GROUP BY \n        m.Frequency, \n        m.Identifier, \n        m.Instrument\n    ORDER BY \n        m.Frequency, \n        m.Identifier, \n        m.Instrument\n\nIn this query, I grouped the data by Frequency, Identifier, and Instrument. In order to get the variable “AuthorShortList” I joined the PI_Info table and the Measurements table on SubjectNumber. I used Concat to make a label for each of the studies with the number of unique ears, the instrument used, and the year and author of the study. My goal was to match the figure created by Voss in 2022, so I filtered for only studies included in that specific plot.\n\nlibrary(ggplot2)\n\n\nggplot(new_table, aes(x = Frequency, y = Mean_Absorption, color = Label)) +\n  geom_line(size = .7, na.rm = TRUE) +  \n  scale_x_log10(name = \"Frequency (Hz)\",\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    labels = c(\"200\", \"400\", \"600\", \"800\", \"1000\", \"2000\", \"4000\", \"6000\", \"8000\")) +\n  scale_y_continuous(\n    name = \"Mean Absorbance\",\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1)  \n  ) +\n  labs(\n    title = \"Mean Absorbance From Each Publication in the WAI Database\",  \n    color = NULL \n  ) +\n  theme_minimal() + \n  theme(\n    axis.text = element_text(size = 5),\n    axis.title = element_text(size = 7),\n    plot.title = element_text(size = 9, face = \"bold\", hjust = .5),\n    legend.text = element_text(size = 5),\n    legend.position = c(0.28, 0.9),\n    legend.key.size = unit(0.1, \"cm\"),\n    legend.spacing = unit(0.01, \"cm\"),\n    legend.background = element_rect(color = \"black\", size = .2, fill = \"white\"),\n    aspect.ratio = 1\n  ) \n\n\n\n\nThis table shows the mean absorbance of frequencies ranging from 200 HZ to 8000 HZ in 12 different studies in the WAI database. As seen in the table, absorbance, on average, increases as frequency increases up until around 1000 HZ, when it drops off and begins to decrease again.\n\nSELECT \n    m.Frequency, \n    s.Sex, \n    AVG(m.Absorbance) AS Avg_Absorbance\nFROM \n    Measurements m\nJOIN \n    Subjects s\nON \n    m.SubjectNumber = s.SubjectNumber\nWHERE \n    m.Identifier = 'Aithal_2015'\n    AND s.Sex != 'Unknown'\n    AND m.Frequency BETWEEN 200 AND 8000\nGROUP BY \n    m.Frequency, s.Sex\nORDER BY \n    m.Frequency, s.Sex;\n\nNow with this SQL query, I am doing a similar thing to the last, except now I am also grouping by “sex” which required me to join the table “Subjects” also in the WAI database. For this table i chose to focus on 1 study in the WAI data base, this being A Comparison With High-Frequency Tympanometry, Automated Brainstem Response, and Transient Evoked and Distortion Product Otoacoustic Emissions(Aithal 2015).\n\ndbDisconnect(con_wai, shutdown = TRUE)\n\n\nlibrary(ggplot2)\n\nggplot(new_table4, aes(x = Frequency, y = Avg_Absorbance, color = Sex)) +\n  geom_line(size = 0.7, na.rm = TRUE) +\n  scale_x_log10(name = \"Frequency (Hz)\",\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    labels = c(\"200\", \"400\", \"600\", \"800\", \"1000\", \"2000\", \"4000\", \"6000\", \"8000\")) +\n  scale_y_continuous(\n    name = \"Average Absorbance\",\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1)\n  ) +\n  labs(\n    title = \"Average Absorbance by Frequency and Gender(Aithal 2015)\",\n    color = NULL \n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_text(size = 8),\n    axis.title = element_text(size = 12),\n    plot.title = element_text(size = 16, face = \"bold\"),\n    legend.text = element_text(size = 8),\n    legend.position = c(0.1, 0.9),\n    legend.box.background = element_rect(color = \"black\", fill = \"white\", size = 0.5) \n  ) +\n  coord_cartesian(xlim = c(200, 8000)) \n\n\n\n\nAgain, this plot shows the average absorbance over frequencies ranging from 200 to 8000. The 2 lines in the plot represent Male and Female tested subjects. As shown by the plot, there is almost no difference in the mean absorbance rates based on gender."
  },
  {
    "objectID": "FinalProject2.html",
    "href": "FinalProject2.html",
    "title": "Spotify Patterns",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readr)\ndataset_2 &lt;- read_csv(\"~/FODS-project2/dataset 2.csv\")\nspotify &lt;- dataset_2\n\nThe dataset that I am using contains a large array of Spotify tracks, spanning over 100 genres and almost 75000 unique tracks. The data was published on Kaggle by Maharshi Pandya in 2022. It is titled “Spotify Tracks Dataset”\nThis is a preview of the data and its variables.\n\nspotify |&gt;\n  head(1)\n\n# A tibble: 1 × 21\n   ...1 track_id   artists album_name track_name popularity duration_ms explicit\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt; &lt;lgl&gt;   \n1     0 5SuOikwiR… Gen Ho… Comedy     Comedy             73      230666 FALSE   \n# ℹ 13 more variables: danceability &lt;dbl&gt;, energy &lt;dbl&gt;, key &lt;dbl&gt;,\n#   loudness &lt;dbl&gt;, mode &lt;dbl&gt;, speechiness &lt;dbl&gt;, acousticness &lt;dbl&gt;,\n#   instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, valence &lt;dbl&gt;, tempo &lt;dbl&gt;,\n#   time_signature &lt;dbl&gt;, track_genre &lt;chr&gt;\n\n\nTo begin, I want to see find the frequency that each artist and each album appears.\n\nartist_freq &lt;- spotify |&gt;\n  count(artists, sort = TRUE)\n\nalbum_freq &lt;- spotify|&gt;\n  count(album_name, sort = TRUE)\n\nNext, we want to see the top 10 most frequently appearing artists and top 10 most frequently appearing albums.\n\ntop10_artists &lt;- head(artist_freq, 10)\n\ntop10_albums &lt;- head(album_freq, 10)\n\nFinally, we can plot these findings on bar charts.\n\nggplot(top10_artists, aes(x = reorder(artists, n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"green\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Frequent Artists\", x = \"Artist\", y = \"Count\")\n\n\n\nggplot(top10_albums, aes(x = reorder(album_name, n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"green\") +\n  coord_flip() +\n  labs(title = \"Top 10 Most Frequent Albums\", x = \"Album Name\", y = \"Count\")\n\n\n\n\nNext, lets look at the song titles. The data set contains a column “popularity_score” that is calculated by spotify software. We want to to see how having certain “buzz words” in a song title affects the songs popularity score.\nTo do this lets first find the words that appear the most frequently in the song titles.\n\nsong_titles &lt;- tolower(spotify$track_name)\n  words &lt;- str_extract_all(song_titles, \"\\\\b\\\\w+(?:'\\\\w+)?\\\\b\")|&gt;\n  unlist()|&gt;\n  as.data.frame()|&gt;\n  setNames(\"word\")|&gt;\n  count(word, sort = TRUE)|&gt;\n  \n    \n  #filter for articles and pronouns\n  filter(!(word %in% \n             c(\"the\", \"a\", \"of\", \"and\", \"you\", \"me\", \"i\", \"to\", \"my\" )))|&gt;\n  arrange(desc(n))|&gt;\n  head(50)\n\nIn the data set, track names contain descriptions for the track such as “live”, “remix”, or “remaster”, which are not necessarily words included in the song title, though they come up as being the most common words. Still, we can see from this table that words like “love”, “Christmas”, “time” and “night” are among the top 50 most common words in song titles.\nWith this, we can look to see if having one of these common “buzz words” in a song title contributes to the popularity score of a given song.\n\nspotify &lt;- spotify |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(has_love = ifelse(str_detect(track_name, regex(\"\\\\blove\\\\b\", ignore_case = TRUE)), \"Yes\", \"No\"))\n\npopularity &lt;- spotify |&gt;\n  group_by(has_love) |&gt;\n  summarise(avg_popularity = mean(popularity, na.rm = TRUE))\n\npopularity |&gt;\nggplot(aes(x = has_love, y = avg_popularity, fill = has_love)) +\n  geom_bar(stat = \"identity\", width = 0.8) +  \n  labs(title = \"Average Popularity of Songs with vs. without 'Love' in Title\",\n       x = \"Contains 'Love'\",\n       y = \"Average Popularity Score\") +\n  scale_fill_manual(values = c(\"Yes\" = \"magenta\", \"No\" = \"lightblue\")) +\n  theme_minimal()\n\n\n\n\nFrom this, we can see songs that contain the word “love” tend to have a higher popularity score on average. Now lest do this with a few of the other most common words.\n\nspotify &lt;- spotify |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(has_christmas = ifelse(str_detect(track_name, regex(\"\\\\bchristmas\\\\b\", ignore_case = TRUE)), \"Yes\", \"No\"))\n\npopularity &lt;- spotify |&gt;\n  group_by(has_christmas) |&gt;\n  summarise(avg_popularity = mean(popularity, na.rm = TRUE))\n\npopularity |&gt;\nggplot(aes(x = has_christmas, y = avg_popularity, fill = has_christmas)) +\n  geom_bar(stat = \"identity\", width = 0.8) +  \n  labs(title = \"Average Popularity of Songs with vs. without 'Christmas' in Title\",\n       x = \"Contains 'Christmas'\",\n       y = \"Average Popularity Score\") +\n  scale_fill_manual(values = c(\"Yes\" = \"red\", \"No\" = \"chartreuse\")) +\n  theme_minimal()\n\n\n\n\n\nspotify &lt;- spotify |&gt;\n  filter(!is.na(track_name)) |&gt;\n  mutate(has_night = ifelse(str_detect(track_name, regex(\"\\\\bnight\\\\b\", ignore_case = TRUE)), \"Yes\", \"No\"))\n\npopularity &lt;- spotify |&gt;\n  group_by(has_night) |&gt;\n  summarise(avg_popularity = mean(popularity, na.rm = TRUE))\n\npopularity |&gt;\nggplot(aes(x = has_night, y = avg_popularity, fill = has_night)) +\n  geom_bar(stat = \"identity\", width = 0.8) +  \n  labs(title = \"Average Popularity of Songs with vs. without 'Night' in Title\",\n       x = \"Contains 'Night'\",\n       y = \"Average Popularity Score\") +\n  scale_fill_manual(values = c(\"Yes\" = \"darkgoldenrod4\", \"No\" = \"burlywood4\")) +\n  theme_minimal()\n\n\n\n\nAs we can see from these charts, song names that contain the word “Christmas” have a much lower popularity score overall, while song names that contain the word “Night”, have just a slightly lower popularity score on average.\nUsing these findings, we can begin to look at the correlation between a songs title and its popularity, maybe leading to findings about how to title songs and what makes the BEST song title."
  },
  {
    "objectID": "ResearchBlog.html",
    "href": "ResearchBlog.html",
    "title": "Daily Research Blog 2025",
    "section": "",
    "text": "Read through the beginning half of PAYS curriculum and took notes in a google doc.\nFinish reading through the rest and take notes on the structure of problems.\nI’m still a little confused about the physical logistics of computers in the classroom. It looks like the students mostly work in groups already, so maybe shared devices with a server connection would work, so every student doesn’t need to download on their own device?"
  },
  {
    "objectID": "ResearchBlog.html#date-may-19-2025",
    "href": "ResearchBlog.html#date-may-19-2025",
    "title": "Daily Research Blog 2025",
    "section": "",
    "text": "Read through the beginning half of PAYS curriculum and took notes in a google doc.\nFinish reading through the rest and take notes on the structure of problems.\nI’m still a little confused about the physical logistics of computers in the classroom. It looks like the students mostly work in groups already, so maybe shared devices with a server connection would work, so every student doesn’t need to download on their own device?"
  },
  {
    "objectID": "Example Problem Integration.html#modeling-growth-and-decay",
    "href": "Example Problem Integration.html#modeling-growth-and-decay",
    "title": "Example Problem Integration",
    "section": "Modeling Growth and Decay",
    "text": "Modeling Growth and Decay"
  },
  {
    "objectID": "ResearchBlog.html#date-may-20th-2025",
    "href": "ResearchBlog.html#date-may-20th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 20th 2025",
    "text": "Date: May 20th 2025\n\nContinued Reading through Pays curriculum. Created an infographic for teaching the difference between Quantitative and Categorical variables. Re-wrote a few problems what used excel in r.\nFind more problems that cant be shifted from excel to r usage.\nHow is material typically taught during the program. Is it similar to a college lecture with slideshow presentation? I wanted to start thinking about teaching materials for information but i realized i not sure how material is usually taught."
  },
  {
    "objectID": "Example Problem Integration.html",
    "href": "Example Problem Integration.html",
    "title": "Example Problem Integration",
    "section": "",
    "text": "**blurb about entering data assigning variable names quotations around character/categorical leave certain blank or give information in a paragraph and have students fill in code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\ndata_frame &lt;- data.frame(Animal = animal, Distance = distance, Time = time)\n\ndata_frame\n\n   Animal Distance Time\n1     Dog     20.0  2.5\n2     Cat     10.0  0.8\n3 Hamster      3.0  0.6\n4   Snail      0.1 10.0\n\n\n\n\n\nintroduce basic tidyverse functions understanding the use of variables for calculation explain use of mutate naming new variable setting equal to its value pipe operator and assigning name to data frame\n\nnew_data &lt;- data_frame |&gt;\n  mutate(speed = Distance / Time)\n\nnew_data\n\n   Animal Distance Time speed\n1     Dog     20.0  2.5  8.00\n2     Cat     10.0  0.8 12.50\n3 Hamster      3.0  0.6  5.00\n4   Snail      0.1 10.0  0.01"
  },
  {
    "objectID": "Example Problem Integration.html#using-r-for-scientific-calculations",
    "href": "Example Problem Integration.html#using-r-for-scientific-calculations",
    "title": "Example Problem Integration",
    "section": "",
    "text": "**blurb about entering data assigning variable names quotations around character/categorical leave certain blank or give information in a paragraph and have students fill in code\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\ndata_frame &lt;- data.frame(Animal = animal, Distance = distance, Time = time)\n\ndata_frame\n\n   Animal Distance Time\n1     Dog     20.0  2.5\n2     Cat     10.0  0.8\n3 Hamster      3.0  0.6\n4   Snail      0.1 10.0\n\n\n\n\n\nintroduce basic tidyverse functions understanding the use of variables for calculation explain use of mutate naming new variable setting equal to its value pipe operator and assigning name to data frame\n\nnew_data &lt;- data_frame |&gt;\n  mutate(speed = Distance / Time)\n\nnew_data\n\n   Animal Distance Time speed\n1     Dog     20.0  2.5  8.00\n2     Cat     10.0  0.8 12.50\n3 Hamster      3.0  0.6  5.00\n4   Snail      0.1 10.0  0.01"
  },
  {
    "objectID": "ExampleProblemIntegration.html",
    "href": "ExampleProblemIntegration.html",
    "title": "Example Problem Integration",
    "section": "",
    "text": "R is a programming language used for statistical analysis, data manipulation, and visualizations. When programming in R, users can work in R studio which provides an accessible platform to write and reproduce code. You will be working in R studio in what is called a Quarto Document to integrate both code and written work and best present your data.\n\n\nWhen beginning to work with a data set, it it important to understand the structure and features that define it. Let’s say you’re working on a science project that is dealing with the speeds of different animals.\nYou’ve measured how long your dog takes to run from the far corner of the back yard to the back door and measured that distance. Your neighbors have agreed to join join experiment and take the same measurements for their pet cat, hamster and snail. It would be same to assume that you want to compare the given speeds of each animal, meaning, in this case, animal type would be your {\\bf unit of observation}. The unit of observation is the variable in your data that is described by the other observations, the unit by which you will analyze your observations.\n\n\n\nLets look at this example by creating a data frame in R. For small data sets such as this one, you can go ahead and enter the observations directly into R. First, begin by creating a new Quarto Document in R studio.\n To start entering data, we need to create a portion of our quarto document that will execute r code. Type “```{r}”, and a grey rectangle should appear on the line that looks something like this.\nNow, anything written in this block should be code in the r programming language. Lets start entering our Data. We have 3 variables in the data we are working with. Animals, our observational unit, Distance, and Time. These are our variable names. We will create objects by assigning the values of our observations to their respective variable with a backwards arrow as shown below.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\n\nHere, we have assigned the observations “Dog”, “Cat”, “Hamster”, and “Snail” to the variable “animal” Now, do the same with the observations for Distance and time. Your work should now look something like this.\n\nlibrary(tidyverse)\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\nNotice how there are no quotation marks around the observations for distance and time. That is because these variable are quantitative, meaning their values represent numerical amounts, as opposed to the variable animal. Animal is a categorical variable, as its observations represent different groups or categories. Finally, we want to arrange these items, so they appear neatly in a data frame. You may have been wondering what this line of code refers to.\n\nlibrary(tidyverse)\n\nThe tidyverse is package in R with tools designed for data wrangling and exploration. We need to install this package and load it into our library in order to use its functions in our code. it is good to note that, once you have installed a package on your device, you only must call call the package from your library to use it again. To combine these objects into a data frame, we will use the tidyverse function “data.frame” and set each object equal to the name of its column. We also want to make sure we assign a name to the object that is created when using the function.\n\nlibrary(tidyverse)\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\ndata_frame &lt;- data.frame(Animal = animal, Distance = distance, Time = time)\n\nNow we have an organized data frame, with all of our variables saves as objects to use for later calculations. If the data you are working with is any larger than a few observations, it is much more practical to type the data into excel and import that file into r. Animal is the observational unit, so this variable should define your rows. Each of the other variables should be labeled at the top of their column. Export your spreadsheet as a csv file and import it into r using this button in the environment tab.\n\nFrom the drop down menu, you should import from excel, and upload your downloaded file. After you import from this screen, your data set will be saved as an object in your environment.\n\n\n\nHere is where r can really start doing the heavy lifting for you Remember, in this example we wanted to compare the given speed of each animal. To do this we must calculate the speed by computing the equation distance/time for each animal. In r, however, you cn write one simple block off code to compute this value for each animal, and also add it as a variable in your data frame. We spoke about the tidyverse earlier and here we will use another one of its data wrangling functions. “Mutate” is a function that allows you create a new column in your data frame based on calculations with other existing variables. In this case we are creating a variable “speed” that is defined by the equation “distance/time”.\n\nnew_data &lt;- data_frame |&gt;\n  mutate(speed = Distance / Time)\n\nnew_data\n\n   Animal Distance Time speed\n1     Dog     20.0  2.5  8.00\n2     Cat     10.0  0.8 12.50\n3 Hamster      3.0  0.6  5.00\n4   Snail      0.1 10.0  0.01\n\n\nWhen using tidyverse functions such as mutate, it is important to use what we call the pipe operator, in order to connect the information from your data set to the next line of code. Think of this symbol “|&gt;” as a link between lines that carries data information. If we were to add additional lines, we would need to include the pip operator at the end of each line."
  },
  {
    "objectID": "ExampleProblemIntegration.html#using-r-for-scientific-calculations",
    "href": "ExampleProblemIntegration.html#using-r-for-scientific-calculations",
    "title": "Example Problem Integration",
    "section": "",
    "text": "R is a programming language used for statistical analysis, data manipulation, and visualizations. When programming in R, users can work in R studio which provides an accessible platform to write and reproduce code. You will be working in R studio in what is called a Quarto Document\n\n\nWhen writing\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\ndata_frame &lt;- data.frame(Animal = animal, Distance = distance, Time = time)\n\ndata_frame\n\n   Animal Distance Time\n1     Dog     20.0  2.5\n2     Cat     10.0  0.8\n3 Hamster      3.0  0.6\n4   Snail      0.1 10.0\n\n\n\n\n\nintroduce basic tidyverse functions understanding the use of variables for calculation explain use of mutate naming new variable setting equal to its value pipe operator and assigning name to data frame\n\nnew_data &lt;- data_frame |&gt;\n  mutate(speed = Distance / Time)\n\nnew_data\n\n   Animal Distance Time speed\n1     Dog     20.0  2.5  8.00\n2     Cat     10.0  0.8 12.50\n3 Hamster      3.0  0.6  5.00\n4   Snail      0.1 10.0  0.01"
  },
  {
    "objectID": "ResearchBlog.html#date-may-21st-2025",
    "href": "ResearchBlog.html#date-may-21st-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 21st 2025",
    "text": "Date: May 21st 2025\n\nRe wrote section 5.2 in Latex and a Quarto document. Marked down and started writing example questions that involved excel usage.\nDiscuss whether I should try to continue in Latex or if it would be beneficial to switch to quarto.\nSame as question 2 but I’m not sure how easy it is to view images in Latex, which makes it difficult to explain certain topics. Its much clearer in a quarto doc, but have to deal with problems of combining work with current curriculum."
  },
  {
    "objectID": "ExampleProblemIntegration.html#using-r-for-data-calculations",
    "href": "ExampleProblemIntegration.html#using-r-for-data-calculations",
    "title": "Example Problem Integration",
    "section": "",
    "text": "R is a programming language used for statistical analysis, data manipulation, and visualizations. When programming in R, users can work in R studio which provides an accessible platform to write and reproduce code. You will be working in R studio in what is called a Quarto Document to integrate both code and written work and best present your data.\n\n\nWhen beginning to work with a data set, it it important to understand the structure and features that define it. Let’s say you’re working on a science project that is dealing with the speeds of different animals.\nYou’ve measured how long your dog takes to run from the far corner of the back yard to the back door and measured that distance. Your neighbors have agreed to join join experiment and take the same measurements for their pet cat, hamster and snail. It would be same to assume that you want to compare the given speeds of each animal, meaning, in this case, animal type would be your {\\bf unit of observation}. The unit of observation is the variable in your data that is described by the other observations, the unit by which you will analyze your observations.\n\n\n\nLets look at this example by creating a data frame in R. For small data sets such as this one, you can go ahead and enter the observations directly into R. First, begin by creating a new Quarto Document in R studio.\n To start entering data, we need to create a portion of our quarto document that will execute r code. Type “```{r}”, and a grey rectangle should appear on the line that looks something like this.\nNow, anything written in this block should be code in the r programming language. Lets start entering our Data. We have 3 variables in the data we are working with. Animals, our observational unit, Distance, and Time. These are our variable names. We will create objects by assigning the values of our observations to their respective variable with a backwards arrow as shown below.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\n\nHere, we have assigned the observations “Dog”, “Cat”, “Hamster”, and “Snail” to the variable “animal” Now, do the same with the observations for Distance and time. Your work should now look something like this.\n\nlibrary(tidyverse)\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\nNotice how there are no quotation marks around the observations for distance and time. That is because these variable are quantitative, meaning their values represent numerical amounts, as opposed to the variable animal. Animal is a categorical variable, as its observations represent different groups or categories. Finally, we want to arrange these items, so they appear neatly in a data frame. You may have been wondering what this line of code refers to.\n\nlibrary(tidyverse)\n\nThe tidyverse is package in R with tools designed for data wrangling and exploration. We need to install this package and load it into our library in order to use its functions in our code. it is good to note that, once you have installed a package on your device, you only must call call the package from your library to use it again. To combine these objects into a data frame, we will use the tidyverse function “data.frame” and set each object equal to the name of its column. We also want to make sure we assign a name to the object that is created when using the function.\n\nlibrary(tidyverse)\n\nanimal &lt;- c(\"Dog\", \"Cat\", \"Hamster\", \"Snail\")\ndistance &lt;- c(20,10,3,.1)\ntime &lt;- c(2.5,.8,.6,10)\n\ndata_frame &lt;- data.frame(Animal = animal, Distance = distance, Time = time)\n\nNow we have an organized data frame, with all of our variables saves as objects to use for later calculations. If the data you are working with is any larger than a few observations, it is much more practical to type the data into excel and import that file into r. Animal is the observational unit, so this variable should define your rows. Each of the other variables should be labeled at the top of their column. Export your spreadsheet as a csv file and import it into r using this button in the environment tab.\n\nFrom the drop down menu, you should import from excel, and upload your downloaded file. After you import from this screen, your data set will be saved as an object in your environment.\n\n\n\nHere is where r can really start doing the heavy lifting for you Remember, in this example we wanted to compare the given speed of each animal. To do this we must calculate the speed by computing the equation distance/time for each animal. In r, however, you cn write one simple block off code to compute this value for each animal, and also add it as a variable in your data frame. We spoke about the tidyverse earlier and here we will use another one of its data wrangling functions. “Mutate” is a function that allows you create a new column in your data frame based on calculations with other existing variables. In this case we are creating a variable “speed” that is defined by the equation “distance/time”.\n\nnew_data &lt;- data_frame |&gt;\n  mutate(speed = Distance / Time)\n\nnew_data\n\n   Animal Distance Time speed\n1     Dog     20.0  2.5  8.00\n2     Cat     10.0  0.8 12.50\n3 Hamster      3.0  0.6  5.00\n4   Snail      0.1 10.0  0.01\n\n\nWhen using tidyverse functions such as mutate, it is important to use what we call the pipe operator, in order to connect the information from your data set to the next line of code. Think of this symbol “|&gt;” as a link between lines that carries data information. If we were to add additional lines, we would need to include the pip operator at the end of each line."
  },
  {
    "objectID": "ResearchBlog.html#date-may-23rd-2025",
    "href": "ResearchBlog.html#date-may-23rd-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 23rd 2025",
    "text": "Date: May 23rd 2025\n\nGave presentation during pizza and progress. Added more to section 5.2 about tidyverse function and their use. Figured out Latex highlighting syntax.\nI will start going through the other examples of excel use in the curriculum and rewrite them in r following the structure i have been using to write 5.2,\nI’m not sure if i like how the highlighting looks when rendered in the pdf. I’m nervous that it looks to dissimilar to r and it will be hard for students to follow. I also don’t love how the future lines are sill very visible so it doesn’t really help to promote the step by step process we were trying to achieve."
  },
  {
    "objectID": "ResearchBlog.html#date-may-27th-2025",
    "href": "ResearchBlog.html#date-may-27th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 27th 2025",
    "text": "Date: May 27th 2025\n\nUpdated some styling choices in 5.2 re write. Took out latex code and just opted for displaying individual steps through lines of r code. Found 2 example problems in the Pays curriculum. Modeling Growth and Decay and Planetary Orbits. Re wrote both problems in r with solutions in all in a pdf.\nStart re write for the Simple Pendulum Problem in pays curriculum which includes work in excel. Also I am going to have someone proof read my writing for grammar and spelling errors and make sure it is digestible for someone with minimal R background.\nIs there an easier way to display an exponential model in r, because right now i am just fitting the curve by linearizing the model first. Also the displaying of the equation is a little difficult in R, but i figure that is also work that will be done on paper and its just helpful to have the solutions all in one place. Also am still a little bit confused (or maybe i forgot) what your goal or vision was for the different documents to come out of this project. Is there a separate one with just solutions or should solutions and questions all be together. And is there a separate doc with interactive prompts for each question, if so that will be next thing on my to-do list for 5.2."
  },
  {
    "objectID": "ResearchBlog.html#date-may-28th-2025",
    "href": "ResearchBlog.html#date-may-28th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 28th 2025",
    "text": "Date: May 28th 2025\n\nI added a section to 5.2 about linear vs. non linear models. Since a lot of the in class activities involve examining either linear or non linear models, i thought it would be important to give the basic instructions here. I want to ask about labeling sections because it could be good to refer back to this specific sections when reading the in class activities. Created pdf for the simple pendulum problem with solutions and instructions. I also started reading some of the material in the data 4 all repo and found a good presentation about asking good questions. I think this could be a good topic for just starting out with data science materials.\nGoing to start forming the interactive versions of each of the in class activities. This will be a qmd file with minimal instructions that students can open up and type directly into. I also need to upload all the example data sets i have created somewhere so that students can access them and don’t have to type data into excel.\nI want to add a section about asking good questions or how to formulate questions about data. I’m not sure if this would be better as something similar to 5.2 where its instructions based. Or have a string of homework problems that outline different data sets and just have students come up with questions and discuss with TA’s and peers. I also think that most of the examples i am re writing come from the in-class activities section of the curriculum so i was wondering if it would it be worth it to just re write that whole section in r. That way there can just be a separate pdf with in class activities."
  },
  {
    "objectID": "ResearchBlog.html#date-may-29th-2025",
    "href": "ResearchBlog.html#date-may-29th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 29th 2025",
    "text": "Date: May 29th 2025\n\nWrote the R integrated version for the radioactive decay in class activity. Then i read and took notes on the data4all lessons to figure out how to formulate questions and lesson plans better. Finally i created an interactive qmd file with some sample homework questions. I broke the questions up into different categories that outline the basic skills expected to be gained from the curriculum.\nI plan start compiling some of the documents I have into one file. Also, now that i have some experience writing interactive forms of questions, I am going to start updating some of the in class activities so there are versions of the files with less writing/explanation and instead just the questions and answers.\nI What will the next steps be in th project? From my perspective, i want to be able to connect all the information needed to complete the in class activities to some sort of interactive homework assignment or lesson. I also think it would be beneficial to have some kinds of visual aids or lesson materials to help foster learning, but i don’t know how cohesive that would be with the structure of the program. maybe the next step is just to condense materials and organize them neatly in github, but also there was maybe ideas of an interactive course site? I would be interested in that."
  },
  {
    "objectID": "ResearchBlog.html#date-may-30th-2025",
    "href": "ResearchBlog.html#date-may-30th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 30th 2025",
    "text": "Date: May 30th 2025\n\nI separated each of the In-Class activities into three different files: activity_intructions, activity_interactive, and activity_solutions. I also create a qmd file for each activity called ICA.activityname.qmd. This file has a short description of the activity and explains how to use the document or where(hypothetically) to find the version you need. I also created separate folders for each of these activities in my work.\nNumber 2 nd 3 kind of go hand in hand today but i need to meet with you to fix some stuff/ discuss where to put datasets to avoid having 2 copies of each one is the repo, because one needs to be in the folder with the activity so it can be read in, but I originally had them all in a folder called datasets, which would have been helpful for organizational purposes.\nI am a little stuck with rendering right now because, for some reason eval: false condition is not working when i am trying to render. I thought maybe it was because my qmd’s didnt have yaml headers but i looked into it and coulnt find anywhere that said that. I also tried adding a header and it did not help. It might be something with the include sytax that i need to update but for now its difficult because lal of my interactive documents hve a lot of un-renderable code… Im sure its probably a simple fix which is why i just focused on writing up all the documents first."
  },
  {
    "objectID": "ResearchBlog.html#date-june-2nd-2025",
    "href": "ResearchBlog.html#date-june-2nd-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 2nd 2025",
    "text": "Date: June 2nd 2025\n\nFinished the integrated documents for all of the in class activities. This included rendering each one to both pdf and html forms. I added an activity for Hooke’s Law and Area of stars, which i previously did not have before. I also created a separate sections for homework problems/assignments in my work. I noticed that a lot of the in class problems, like the in class activities, have a way of being integrated to R. For the in class problem on modeling growth and decay, i combined documents the same way, minus the instructions, so the final pdf just contains the homework questions in an interactive format, and the solutions.\nI am going complete writing the pre work questions for each of the in class assignments. I already have a few basic homework assignments that are designed to teach R but i think i want to split them up into individual questions so they can be referenced the same way the PAYS schedule references individual problems.\nI am starting to think about data Saturdays and what examples might be good for getting students interested in the data. I think sports data could be really good for reaching a large audience of interests and im sure there is a lot of it out there. But i wonder if you think it would be good to stick to larger examples( like the data4all lessons) in order to create a more cohesive lesson."
  },
  {
    "objectID": "ResearchBlog.html#date-june-3rd",
    "href": "ResearchBlog.html#date-june-3rd",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 3rd",
    "text": "Date: June 3rd\n\nRead through the data4all evaluation and took notes. I stated writing a document called goals and logistics to start thinking about data days and how we want that program to be run. This information can also help inform the choices and steps we take with the PAYS program as well.\nI found a few new sources that are high school data science programs and i want to make sure i get information from as many different places as possible so i can decide what actually will work for us and our goals.\nIm not really confused about anything right now but i do want to pitch a lot of my ideas for the structure of data days. I know we talked about a fwe things so i tried to come up with some concrete structure things that would help with starting to write content for the program."
  },
  {
    "objectID": "ResearchBlog.html#date-june-4th",
    "href": "ResearchBlog.html#date-june-4th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 4th",
    "text": "Date: June 4th\n\nStarted Looking into how to form the less on plan around city planning. I begin with a rough outline of the Week structure with topics for lessons and the skills that should be gained throughout the weeks. Now i’ve begun trying to piece the story together through datasets. Ive wrote the structure of the first lesson dealing with the history of the city plan in Los Angeles. I also started making the presentation for friday. I wanted to talk about the goals for the curriculum and why whose are our goals. Also the plans we have to achieve them through specific areas of the curriculum.\nGoing to continue searching for relevant data sets and trying to come up with creative activities to help continue telling hte story of city planning data.\nI am wondering who would mostly be teaching and instructing these saturday workshops. Would it mostly be professors, or would studetns be leading a lot of the activities. I think it could be helpful to have a student mentor program but i dont know how much work people would be willing to do."
  },
  {
    "objectID": "ResearchBlog.html#date-may-19",
    "href": "ResearchBlog.html#date-may-19",
    "title": "Daily Research Blog 2025",
    "section": "",
    "text": "Read through the beginning half of PAYS curriculum and took notes in a google doc.\nFinish reading through the rest and take notes on the structure of problems.\nI’m still a little confused about the physical logistics of computers in the classroom. It looks like the students mostly work in groups already, so maybe shared devices with a server connection would work, so every student doesn’t need to download on their own device?"
  },
  {
    "objectID": "ResearchBlog.html#date-may-20th",
    "href": "ResearchBlog.html#date-may-20th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 20th",
    "text": "Date: May 20th\n\nContinued Reading through Pays curriculum. Created an infographic for teaching the difference between Quantitative and Categorical variables. Re-wrote a few problems what used excel in r.\nFind more problems that cant be shifted from excel to r usage.\nHow is material typically taught during the program. Is it similar to a college lecture with slideshow presentation? I wanted to start thinking about teaching materials for information but i realized i not sure how material is usually taught."
  },
  {
    "objectID": "ResearchBlog.html#date-may-21st",
    "href": "ResearchBlog.html#date-may-21st",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 21st",
    "text": "Date: May 21st\n\nRe wrote section 5.2 in Latex and a Quarto document. Marked down and started writing example questions that involved excel usage.\nDiscuss whether I should try to continue in Latex or if it would be beneficial to switch to quarto.\nSame as question 2 but I’m not sure how easy it is to view images in Latex, which makes it difficult to explain certain topics. Its much clearer in a quarto doc, but have to deal with problems of combining work with current curriculum."
  },
  {
    "objectID": "ResearchBlog.html#date-may-23rd",
    "href": "ResearchBlog.html#date-may-23rd",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 23rd",
    "text": "Date: May 23rd\n\nGave presentation during pizza and progress. Added more to section 5.2 about tidyverse function and their use. Figured out Latex highlighting syntax.\nI will start going through the other examples of excel use in the curriculum and rewrite them in r following the structure i have been using to write 5.2,\nI’m not sure if i like how the highlighting looks when rendered in the pdf. I’m nervous that it looks to dissimilar to r and it will be hard for students to follow. I also don’t love how the future lines are sill very visible so it doesn’t really help to promote the step by step process we were trying to achieve."
  },
  {
    "objectID": "ResearchBlog.html#date-may-27th",
    "href": "ResearchBlog.html#date-may-27th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 27th",
    "text": "Date: May 27th\n\nUpdated some styling choices in 5.2 re write. Took out latex code and just opted for displaying individual steps through lines of r code. Found 2 example problems in the Pays curriculum. Modeling Growth and Decay and Planetary Orbits. Re wrote both problems in r with solutions in all in a pdf.\nStart re write for the Simple Pendulum Problem in pays curriculum which includes work in excel. Also I am going to have someone proof read my writing for grammar and spelling errors and make sure it is digestible for someone with minimal R background.\nIs there an easier way to display an exponential model in r, because right now i am just fitting the curve by linearizing the model first. Also the displaying of the equation is a little difficult in R, but i figure that is also work that will be done on paper and its just helpful to have the solutions all in one place. Also am still a little bit confused (or maybe i forgot) what your goal or vision was for the different documents to come out of this project. Is there a separate one with just solutions or should solutions and questions all be together. And is there a separate doc with interactive prompts for each question, if so that will be next thing on my to-do list for 5.2."
  },
  {
    "objectID": "ResearchBlog.html#date-may-28th",
    "href": "ResearchBlog.html#date-may-28th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 28th",
    "text": "Date: May 28th\n\nI added a section to 5.2 about linear vs. non linear models. Since a lot of the in class activities involve examining either linear or non linear models, i thought it would be important to give the basic instructions here. I want to ask about labeling sections because it could be good to refer back to this specific sections when reading the in class activities. Created pdf for the simple pendulum problem with solutions and instructions. I also started reading some of the material in the data 4 all repo and found a good presentation about asking good questions. I think this could be a good topic for just starting out with data science materials.\nGoing to start forming the interactive versions of each of the in class activities. This will be a qmd file with minimal instructions that students can open up and type directly into. I also need to upload all the example data sets i have created somewhere so that students can access them and don’t have to type data into excel.\nI want to add a section about asking good questions or how to formulate questions about data. I’m not sure if this would be better as something similar to 5.2 where its instructions based. Or have a string of homework problems that outline different data sets and just have students come up with questions and discuss with TA’s and peers. I also think that most of the examples i am re writing come from the in-class activities section of the curriculum so i was wondering if it would it be worth it to just re write that whole section in r. That way there can just be a separate pdf with in class activities."
  },
  {
    "objectID": "ResearchBlog.html#date-may-29th",
    "href": "ResearchBlog.html#date-may-29th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 29th",
    "text": "Date: May 29th\n\nWrote the R integrated version for the radioactive decay in class activity. Then i read and took notes on the data4all lessons to figure out how to formulate questions and lesson plans better. Finally i created an interactive qmd file with some sample homework questions. I broke the questions up into different categories that outline the basic skills expected to be gained from the curriculum.\nI plan start compiling some of the documents I have into one file. Also, now that i have some experience writing interactive forms of questions, I am going to start updating some of the in class activities so there are versions of the files with less writing/explanation and instead just the questions and answers.\nI What will the next steps be in th project? From my perspective, i want to be able to connect all the information needed to complete the in class activities to some sort of interactive homework assignment or lesson. I also think it would be beneficial to have some kinds of visual aids or lesson materials to help foster learning, but i don’t know how cohesive that would be with the structure of the program. maybe the next step is just to condense materials and organize them neatly in github, but also there was maybe ideas of an interactive course site? I would be interested in that."
  },
  {
    "objectID": "ResearchBlog.html#date-may-30th",
    "href": "ResearchBlog.html#date-may-30th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 30th",
    "text": "Date: May 30th\n\nI separated each of the In-Class activities into three different files: activity_intructions, activity_interactive, and activity_solutions. I also create a qmd file for each activity called ICA.activityname.qmd. This file has a short description of the activity and explains how to use the document or where(hypothetically) to find the version you need. I also created separate folders for each of these activities in my work.\nNumber 2 nd 3 kind of go hand in hand today but i need to meet with you to fix some stuff/ discuss where to put datasets to avoid having 2 copies of each one is the repo, because one needs to be in the folder with the activity so it can be read in, but I originally had them all in a folder called datasets, which would have been helpful for organizational purposes.\nI am a little stuck with rendering right now because, for some reason eval: false condition is not working when i am trying to render. I thought maybe it was because my qmd’s didnt have yaml headers but i looked into it and coulnt find anywhere that said that. I also tried adding a header and it did not help. It might be something with the include sytax that i need to update but for now its difficult because lal of my interactive documents hve a lot of un-renderable code… Im sure its probably a simple fix which is why i just focused on writing up all the documents first."
  },
  {
    "objectID": "ResearchBlog.html#date-june-2nd",
    "href": "ResearchBlog.html#date-june-2nd",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 2nd",
    "text": "Date: June 2nd\n\nFinished the integrated documents for all of the in class activities. This included rendering each one to both pdf and html forms. I added an activity for Hooke’s Law and Area of stars, which i previously did not have before. I also created a separate sections for homework problems/assignments in my work. I noticed that a lot of the in class problems, like the in class activities, have a way of being integrated to R. For the in class problem on modeling growth and decay, i combined documents the same way, minus the instructions, so the final pdf just contains the homework questions in an interactive format, and the solutions.\nI am going complete writing the pre work questions for each of the in class assignments. I already have a few basic homework assignments that are designed to teach R but i think i want to split them up into individual questions so they can be referenced the same way the PAYS schedule references individual problems.\nI am starting to think about data Saturdays and what examples might be good for getting students interested in the data. I think sports data could be really good for reaching a large audience of interests and im sure there is a lot of it out there. But i wonder if you think it would be good to stick to larger examples( like the data4all lessons) in order to create a more cohesive lesson."
  },
  {
    "objectID": "ResearchBlog.html#date-june-5th",
    "href": "ResearchBlog.html#date-june-5th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 5th",
    "text": "Date: June 5th\n\nToday i began writing a lesson plan based around the ca_tes data set from american forests tree canopy data. The lesson starts with an introduction on why i city planning to display data science. It then goes into the meaning behind the dataset and the real-world applications of solutions. It then goes into viewing the data set, learning what an observation and observational unit is. Next, i discuss the process of questioning a data set, and learning to create informed SMART questions. The presentation then discusses the process of data wrangling using examples from the ca_tes data set. And finally i have created a few example visualizations to discuss the importance of meaningfully expressing and communicating your findings. This may not be the end of the lesson and there definitely is more room to add content but so far i’ve created somewhat of a basic structure for the lesson.\nI need to finish the presentation for pizza and progess, specifically pick a few examples from the lesson and explain how they connect to the goals of the project.\nI am trying to figure out a way to implement the mathlink cubes lesson into the full lesson plan."
  },
  {
    "objectID": "ResearchBlog.html#date-june-6th",
    "href": "ResearchBlog.html#date-june-6th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 6th",
    "text": "Date: June 6th\n\nFinished presentation for pizza and progress. Created California heat map by joining the census data with the tes data set. After finding and figuring out how to use the census data i created a few data wrangling examples in the lesson plan for Saturdays. I also changed the format of the saturday lesson plan. Instead of starting with examples usages for the data verbs, i created a portion where the students would do an activity involving the mathlink cubes. I explained how they work and how they represent a data set. Then i prompt students to think about the data verbs intuitively(what you think they might mean) before giving them the definition and prompting them to physically recreate the wrangling with the cubes.\nBegin creating a lesson with another example and new data. I could stick with the topic of city planning and do something else like traffic or transportation data, or i might shift completely.\nDepending on the structure of the Saturdays, i will make the lessons completely different. If the workshops are going to be close in date and we expect relatively the same students to show up, then i will probably keep with the same example and add onto it to dive deeper into the data and teach more complex applications. But if each of the Saturdays are going to be completely separate, then i will probably just come up with a new example, reteaching the basic concepts i went over in the initial tree coverage lesson."
  },
  {
    "objectID": "ResearchBlog.html#date-june-9th",
    "href": "ResearchBlog.html#date-june-9th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 9th",
    "text": "Date: June 9th\n\nI updated some of the lesson plan for the tes example. For example i finished my infographic teaching variable types and uploaded that to a slide. Then i figured out how to create the github website and link it to a repo i created in the DS4HS org. As far as i know, it it able to be accessed publicly I worked on creating the next portion of the lesson on student projects and presentation.\nStart creating the teaching materials for the lesson. This will involve creating a pdf document that has the title of each slide and what information needs to be grasped from it. It will also include notes on important things to mention that are not included in the slides and also prompting the start of physical activities and student group work.\nWhat is the theme of your website called. I looked through all the quarto built in themes and i couldn’t find it so i figured it was most likely custom. None of the given themes are amazing so i choose a pretty basic one. Also, is there a way to get r code to animate as a bullet point so it shows up after certain information on a slide or is it easier to just include the code on the following slide. this is for when i am presenting data wrangling questions and don’t want the solution to show until students have had the chance to discuss. Also, can i change the size of photos in the presentation, they all render too small."
  },
  {
    "objectID": "ResearchBlog.html#date-june-10th",
    "href": "ResearchBlog.html#date-june-10th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 10th",
    "text": "Date: June 10th\n\nToday I mostly worked on style updates to the website. I played around with a lot of the coloring and the font and changing the placement of the titles in the nav bar. I also created a logo for the program though i am open to work shopping its design (its pretty basic). I added a short introduction to the materials on the home page of the website explaining the goals of the program and where to find certain resources. Then i made some more edits to the tree equity lesson. I updated slides where i wanted r code to show incrementally. I was able to get the presentation to render as slides on the website instead of html and i looked into the multiple formats option but the code that i found didnt render correctly. Finally, i started writing the teaching materials for the tree equity lesson. I am just rendering this to a page on the website but i wonder if it would be better as a link to the pdf, or maybe include a download link at the top of page.\nFinish writing the instructor guide for the tree Lesson and then proofread my work from 5.2. 3. For some reason the hover color for the pages in my navbar is showing as a still rectangle over the title of the page, which makes the text illegible. I tried deconstructing my .css file but when i added everything back that i did want to include, the highlight comes back and im not sure how to fix. I also remember talking about doing the thing where you link files of different formats in the same file but i cant remeber where that was applicable so i didnge get to it today. ## Date: June 11th\nToday I finished the teaching materials for the Tree Equity Lesson. I did some more research about the mathlink cubes in order to explain the activity with them better. I also made a lot of style changes to the website.\nI am going to start working on another similar example to the tree lesson. I want to do something related to public transportation or traffic data but i think public transportation will have more applicable reasoning and results.\nI am still struggling with rendering to multiple formats. When i render, the html page has the other formats tab and it has the pdf linked but the pdf doesnt render correctly. I looked into it and found that having html specific syntax will not render to pdf so i tried something in the yaml to override that, but that did not work either."
  },
  {
    "objectID": "ResearchBlog.html#date-june-12th",
    "href": "ResearchBlog.html#date-june-12th",
    "title": "Daily Research Blog 2025",
    "section": "Date June 12th",
    "text": "Date June 12th\n\nI worked on finding the datasets I want to use for the lesson on public transport. It was a little difficult because a lot of the data is not complete for multiple years. I found one dataset that have information on public transportation usage from 2014-2024 but the variables are limited to ridership and mileage, not much useful information for analysis. However, I am going to include some sort of join portion in the lesson to join this data with census data in order to conduct a more useful analysis.\nContinue search for helpful data sets and begin writing the lesson on public transportation\nI am still trying to figure out what I want the exact structure of the lesson to be. I know i want to include a little mre nuances questions about the data and some more advanced data wrangling topics but I am not exactly sure how that is going to look. I think running a regression to create a model for ridership over time could be a more intermediate to advanced skill that would fit that data I have well but I also want the results of the analysis to be a little more interesting."
  },
  {
    "objectID": "ResearchBlog.html#date-june-13th",
    "href": "ResearchBlog.html#date-june-13th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 13th",
    "text": "Date: June 13th\n\nToday I worked on the lesson for Public Transportation. First, I narrowed down the initial data set to just CA public transit systems so that it is easier to work with. I made sure to include in the instructor manual how to filter initial data to be specific to your state so it is relevant to the students. The lesson starts off with an introduction to the variables and the dataset like before, but then instead of getting into questions about the data, first students will join census data from ca with information on race, income, unemp, and other socioeconomic factors to the transportation data for a more in depth analysis. I also created an initial basic example plotting the difference ca agencies and their total riders over time.\nI am going to start writing the parts of the lesson that require analysis in relation to socioeconomic factors. Hopefully I was be able to create a map plot to look at accessibility of public transit in different areas and compare this to the socioeconomic factors in that area. This will then guide further analysis on those relationships.\nI need to think through how to structure the activities using the spatial data so they are approachable for high school students. Some of the code is a little bit difficult to understand(such as facet and leaflet)"
  },
  {
    "objectID": "ResearchBlog.html#date-june-16th-2025",
    "href": "ResearchBlog.html#date-june-16th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 16th 2025",
    "text": "Date: June 16th 2025\n\nToday i found another dataset that has California public transportation data with data about public transit stops. I did a lot of wrangling on this data set so i could combine it with the geography of the census tract. And then I cleaned a version of the tidycensus data and saved it as a csv. So now i have a dataset with transit data and geography(geoid as well) and a data set with census data and geography. Hopefully this will make for a good and simple enough lesson on joining and potential map visualizations.\nFinish the interactive tree lesson worksheet. I started work on it today and I just have to add the last problem. 3.In my transit data set, each stop has a value for the variable n_hours_in_service. A lot of stops have 0 for this value meaning they aren’t ever stopped at I assume? Should this be factored into calculations(because it says something about lack of stops) or would that make results look skewed. What other variables should I pull from tidycensus to allow for more in depth exploration. Because the data requires so much cleaning, i think it will be hard for this lesson to have students doing an individual project with their own dataset. That is why i want the original dataset they see in class to be comprehensive enough to have a different research question for all the students/groups in the class."
  },
  {
    "objectID": "ResearchBlog.html#date-june-17-2025",
    "href": "ResearchBlog.html#date-june-17-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 17 2025",
    "text": "Date: June 17 2025\n\nI worked on writing the qmd file for the students presentation. I basically just gave them space to make a 4 slide presentation with the first slide being their research question and data, the second being their wrangling process, the third being their ggplot code and plot, and the 4th is their insights and the trends they notices from the plot. I gave a quick instruction slide that i noted should be deleted before they render. I wanted to make the presentations pretty short and uniform so its east to get through if we have a shorter day. I then worked with the mathlink cubes for a while, taking pictures of all of the different data wrangling processes and the solutions for the questions used in the tree lecture. I also wrote instructions and took pictures that explain how to put the cubes together in a data like structure thats easy for students to take a part. Finally, I did a little more work on the public transit lesson, writing the next part of the lecture that involved joining the census data with the spatial transit data.\nI will use the mathlink cubes to represent and teach the process of joining since this goes right at the spot of the lecture i am currently writing.\nI’m not exactly sure if i am representing group_by and summarize correctly with the mathlink cubes. The example in the article is kind of confusing and I’m not really understanding what they are summarizing. I did group_by a certain color, and then organized that colors column by each shape in the column, but then when i summarise, im not sure if I should leave the rows where a shape repeats or if those would get filtered out with the group_by."
  }
]