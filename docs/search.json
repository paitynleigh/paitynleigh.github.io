[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "hahahahhahha im evil lollllllowoahfbu3iebfuwbeiw",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "ResearchBlog.html",
    "href": "ResearchBlog.html",
    "title": "Daily Research Blog 2025",
    "section": "",
    "text": "Read through the beginning half of PAYS curriculum and took notes in a google doc.\nFinish reading through the rest and take notes on the structure of problems.\nI’m still a little confused about the physical logistics of computers in the classroom. It looks like the students mostly work in groups already, so maybe shared devices with a server connection would work, so every student doesn’t need to download on their own device?"
  },
  {
    "objectID": "ResearchBlog.html#date-may-19",
    "href": "ResearchBlog.html#date-may-19",
    "title": "Daily Research Blog 2025",
    "section": "",
    "text": "Read through the beginning half of PAYS curriculum and took notes in a google doc.\nFinish reading through the rest and take notes on the structure of problems.\nI’m still a little confused about the physical logistics of computers in the classroom. It looks like the students mostly work in groups already, so maybe shared devices with a server connection would work, so every student doesn’t need to download on their own device?"
  },
  {
    "objectID": "ResearchBlog.html#date-may-20th",
    "href": "ResearchBlog.html#date-may-20th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 20th",
    "text": "Date: May 20th\n\nContinued Reading through Pays curriculum. Created an infographic for teaching the difference between Quantitative and Categorical variables. Re-wrote a few problems what used excel in r.\nFind more problems that cant be shifted from excel to r usage.\nHow is material typically taught during the program. Is it similar to a college lecture with slideshow presentation? I wanted to start thinking about teaching materials for information but i realized i not sure how material is usually taught."
  },
  {
    "objectID": "ResearchBlog.html#date-may-21st",
    "href": "ResearchBlog.html#date-may-21st",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 21st",
    "text": "Date: May 21st\n\nRe wrote section 5.2 in Latex and a Quarto document. Marked down and started writing example questions that involved excel usage.\nDiscuss whether I should try to continue in Latex or if it would be beneficial to switch to quarto.\nSame as question 2 but I’m not sure how easy it is to view images in Latex, which makes it difficult to explain certain topics. Its much clearer in a quarto doc, but have to deal with problems of combining work with current curriculum."
  },
  {
    "objectID": "ResearchBlog.html#date-may-23rd",
    "href": "ResearchBlog.html#date-may-23rd",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 23rd",
    "text": "Date: May 23rd\n\nGave presentation during pizza and progress. Added more to section 5.2 about tidyverse function and their use. Figured out Latex highlighting syntax.\nI will start going through the other examples of excel use in the curriculum and rewrite them in r following the structure i have been using to write 5.2,\nI’m not sure if i like how the highlighting looks when rendered in the pdf. I’m nervous that it looks to dissimilar to r and it will be hard for students to follow. I also don’t love how the future lines are sill very visible so it doesn’t really help to promote the step by step process we were trying to achieve."
  },
  {
    "objectID": "ResearchBlog.html#date-may-27th",
    "href": "ResearchBlog.html#date-may-27th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 27th",
    "text": "Date: May 27th\n\nUpdated some styling choices in 5.2 re write. Took out latex code and just opted for displaying individual steps through lines of r code. Found 2 example problems in the Pays curriculum. Modeling Growth and Decay and Planetary Orbits. Re wrote both problems in r with solutions in all in a pdf.\nStart re write for the Simple Pendulum Problem in pays curriculum which includes work in excel. Also I am going to have someone proof read my writing for grammar and spelling errors and make sure it is digestible for someone with minimal R background.\nIs there an easier way to display an exponential model in r, because right now i am just fitting the curve by linearizing the model first. Also the displaying of the equation is a little difficult in R, but i figure that is also work that will be done on paper and its just helpful to have the solutions all in one place. Also am still a little bit confused (or maybe i forgot) what your goal or vision was for the different documents to come out of this project. Is there a separate one with just solutions or should solutions and questions all be together. And is there a separate doc with interactive prompts for each question, if so that will be next thing on my to-do list for 5.2."
  },
  {
    "objectID": "ResearchBlog.html#date-may-28th",
    "href": "ResearchBlog.html#date-may-28th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 28th",
    "text": "Date: May 28th\n\nI added a section to 5.2 about linear vs. non linear models. Since a lot of the in class activities involve examining either linear or non linear models, i thought it would be important to give the basic instructions here. I want to ask about labeling sections because it could be good to refer back to this specific sections when reading the in class activities. Created pdf for the simple pendulum problem with solutions and instructions. I also started reading some of the material in the data 4 all repo and found a good presentation about asking good questions. I think this could be a good topic for just starting out with data science materials.\nGoing to start forming the interactive versions of each of the in class activities. This will be a qmd file with minimal instructions that students can open up and type directly into. I also need to upload all the example data sets i have created somewhere so that students can access them and don’t have to type data into excel.\nI want to add a section about asking good questions or how to formulate questions about data. I’m not sure if this would be better as something similar to 5.2 where its instructions based. Or have a string of homework problems that outline different data sets and just have students come up with questions and discuss with TA’s and peers. I also think that most of the examples i am re writing come from the in-class activities section of the curriculum so i was wondering if it would it be worth it to just re write that whole section in r. That way there can just be a separate pdf with in class activities."
  },
  {
    "objectID": "ResearchBlog.html#date-may-29th",
    "href": "ResearchBlog.html#date-may-29th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 29th",
    "text": "Date: May 29th\n\nWrote the R integrated version for the radioactive decay in class activity. Then i read and took notes on the data4all lessons to figure out how to formulate questions and lesson plans better. Finally i created an interactive qmd file with some sample homework questions. I broke the questions up into different categories that outline the basic skills expected to be gained from the curriculum.\nI plan start compiling some of the documents I have into one file. Also, now that i have some experience writing interactive forms of questions, I am going to start updating some of the in class activities so there are versions of the files with less writing/explanation and instead just the questions and answers.\nI What will the next steps be in th project? From my perspective, i want to be able to connect all the information needed to complete the in class activities to some sort of interactive homework assignment or lesson. I also think it would be beneficial to have some kinds of visual aids or lesson materials to help foster learning, but i don’t know how cohesive that would be with the structure of the program. maybe the next step is just to condense materials and organize them neatly in github, but also there was maybe ideas of an interactive course site? I would be interested in that."
  },
  {
    "objectID": "ResearchBlog.html#date-may-30th",
    "href": "ResearchBlog.html#date-may-30th",
    "title": "Daily Research Blog 2025",
    "section": "Date: May 30th",
    "text": "Date: May 30th\n\nI separated each of the In-Class activities into three different files: activity_intructions, activity_interactive, and activity_solutions. I also create a qmd file for each activity called ICA.activityname.qmd. This file has a short description of the activity and explains how to use the document or where(hypothetically) to find the version you need. I also created separate folders for each of these activities in my work.\nNumber 2 nd 3 kind of go hand in hand today but i need to meet with you to fix some stuff/ discuss where to put datasets to avoid having 2 copies of each one is the repo, because one needs to be in the folder with the activity so it can be read in, but I originally had them all in a folder called datasets, which would have been helpful for organizational purposes.\nI am a little stuck with rendering right now because, for some reason eval: false condition is not working when i am trying to render. I thought maybe it was because my qmd’s didnt have yaml headers but i looked into it and coulnt find anywhere that said that. I also tried adding a header and it did not help. It might be something with the include sytax that i need to update but for now its difficult because lal of my interactive documents hve a lot of un-renderable code… Im sure its probably a simple fix which is why i just focused on writing up all the documents first."
  },
  {
    "objectID": "ResearchBlog.html#date-june-2nd",
    "href": "ResearchBlog.html#date-june-2nd",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 2nd",
    "text": "Date: June 2nd\n\nFinished the integrated documents for all of the in class activities. This included rendering each one to both pdf and html forms. I added an activity for Hooke’s Law and Area of stars, which i previously did not have before. I also created a separate sections for homework problems/assignments in my work. I noticed that a lot of the in class problems, like the in class activities, have a way of being integrated to R. For the in class problem on modeling growth and decay, i combined documents the same way, minus the instructions, so the final pdf just contains the homework questions in an interactive format, and the solutions.\nI am going complete writing the pre work questions for each of the in class assignments. I already have a few basic homework assignments that are designed to teach R but i think i want to split them up into individual questions so they can be referenced the same way the PAYS schedule references individual problems.\nI am starting to think about data Saturdays and what examples might be good for getting students interested in the data. I think sports data could be really good for reaching a large audience of interests and im sure there is a lot of it out there. But i wonder if you think it would be good to stick to larger examples( like the data4all lessons) in order to create a more cohesive lesson."
  },
  {
    "objectID": "ResearchBlog.html#date-june-3rd",
    "href": "ResearchBlog.html#date-june-3rd",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 3rd",
    "text": "Date: June 3rd\n\nRead through the data4all evaluation and took notes. I stated writing a document called goals and logistics to start thinking about data days and how we want that program to be run. This information can also help inform the choices and steps we take with the PAYS program as well.\nI found a few new sources that are high school data science programs and i want to make sure i get information from as many different places as possible so i can decide what actually will work for us and our goals.\nIm not really confused about anything right now but i do want to pitch a lot of my ideas for the structure of data days. I know we talked about a fwe things so i tried to come up with some concrete structure things that would help with starting to write content for the program."
  },
  {
    "objectID": "ResearchBlog.html#date-june-4th",
    "href": "ResearchBlog.html#date-june-4th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 4th",
    "text": "Date: June 4th\n\nStarted Looking into how to form the less on plan around city planning. I begin with a rough outline of the Week structure with topics for lessons and the skills that should be gained throughout the weeks. Now i’ve begun trying to piece the story together through datasets. Ive wrote the structure of the first lesson dealing with the history of the city plan in Los Angeles. I also started making the presentation for friday. I wanted to talk about the goals for the curriculum and why whose are our goals. Also the plans we have to achieve them through specific areas of the curriculum.\nGoing to continue searching for relevant data sets and trying to come up with creative activities to help continue telling hte story of city planning data.\nI am wondering who would mostly be teaching and instructing these saturday workshops. Would it mostly be professors, or would studetns be leading a lot of the activities. I think it could be helpful to have a student mentor program but i dont know how much work people would be willing to do."
  },
  {
    "objectID": "ResearchBlog.html#date-june-5th",
    "href": "ResearchBlog.html#date-june-5th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 5th",
    "text": "Date: June 5th\n\nToday i began writing a lesson plan based around the ca_tes data set from american forests tree canopy data. The lesson starts with an introduction on why i city planning to display data science. It then goes into the meaning behind the dataset and the real-world applications of solutions. It then goes into viewing the data set, learning what an observation and observational unit is. Next, i discuss the process of questioning a data set, and learning to create informed SMART questions. The presentation then discusses the process of data wrangling using examples from the ca_tes data set. And finally i have created a few example visualizations to discuss the importance of meaningfully expressing and communicating your findings. This may not be the end of the lesson and there definitely is more room to add content but so far i’ve created somewhat of a basic structure for the lesson.\nI need to finish the presentation for pizza and progess, specifically pick a few examples from the lesson and explain how they connect to the goals of the project.\nI am trying to figure out a way to implement the mathlink cubes lesson into the full lesson plan."
  },
  {
    "objectID": "ResearchBlog.html#date-june-6th",
    "href": "ResearchBlog.html#date-june-6th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 6th",
    "text": "Date: June 6th\n\nFinished presentation for pizza and progress. Created California heat map by joining the census data with the tes data set. After finding and figuring out how to use the census data i created a few data wrangling examples in the lesson plan for Saturdays. I also changed the format of the saturday lesson plan. Instead of starting with examples usages for the data verbs, i created a portion where the students would do an activity involving the mathlink cubes. I explained how they work and how they represent a data set. Then i prompt students to think about the data verbs intuitively(what you think they might mean) before giving them the definition and prompting them to physically recreate the wrangling with the cubes.\nBegin creating a lesson with another example and new data. I could stick with the topic of city planning and do something else like traffic or transportation data, or i might shift completely.\nDepending on the structure of the Saturdays, i will make the lessons completely different. If the workshops are going to be close in date and we expect relatively the same students to show up, then i will probably keep with the same example and add onto it to dive deeper into the data and teach more complex applications. But if each of the Saturdays are going to be completely separate, then i will probably just come up with a new example, reteaching the basic concepts i went over in the initial tree coverage lesson."
  },
  {
    "objectID": "ResearchBlog.html#date-june-9th",
    "href": "ResearchBlog.html#date-june-9th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 9th",
    "text": "Date: June 9th\n\nI updated some of the lesson plan for the tes example. For example i finished my infographic teaching variable types and uploaded that to a slide. Then i figured out how to create the github website and link it to a repo i created in the DS4HS org. As far as i know, it it able to be accessed publicly I worked on creating the next portion of the lesson on student projects and presentation.\nStart creating the teaching materials for the lesson. This will involve creating a pdf document that has the title of each slide and what information needs to be grasped from it. It will also include notes on important things to mention that are not included in the slides and also prompting the start of physical activities and student group work.\nWhat is the theme of your website called. I looked through all the quarto built in themes and i couldn’t find it so i figured it was most likely custom. None of the given themes are amazing so i choose a pretty basic one. Also, is there a way to get r code to animate as a bullet point so it shows up after certain information on a slide or is it easier to just include the code on the following slide. this is for when i am presenting data wrangling questions and don’t want the solution to show until students have had the chance to discuss. Also, can i change the size of photos in the presentation, they all render too small."
  },
  {
    "objectID": "ResearchBlog.html#date-june-10th",
    "href": "ResearchBlog.html#date-june-10th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 10th",
    "text": "Date: June 10th\n\nToday I mostly worked on style updates to the website. I played around with a lot of the coloring and the font and changing the placement of the titles in the nav bar. I also created a logo for the program though i am open to work shopping its design (its pretty basic). I added a short introduction to the materials on the home page of the website explaining the goals of the program and where to find certain resources. Then i made some more edits to the tree equity lesson. I updated slides where i wanted r code to show incrementally. I was able to get the presentation to render as slides on the website instead of html and i looked into the multiple formats option but the code that i found didnt render correctly. Finally, i started writing the teaching materials for the tree equity lesson. I am just rendering this to a page on the website but i wonder if it would be better as a link to the pdf, or maybe include a download link at the top of page.\nFinish writing the instructor guide for the tree Lesson and then proofread my work from 5.2. 3. For some reason the hover color for the pages in my navbar is showing as a still rectangle over the title of the page, which makes the text illegible. I tried deconstructing my .css file but when i added everything back that i did want to include, the highlight comes back and im not sure how to fix. I also remember talking about doing the thing where you link files of different formats in the same file but i cant remeber where that was applicable so i didnge get to it today. ## Date: June 11th\nToday I finished the teaching materials for the Tree Equity Lesson. I did some more research about the mathlink cubes in order to explain the activity with them better. I also made a lot of style changes to the website.\nI am going to start working on another similar example to the tree lesson. I want to do something related to public transportation or traffic data but i think public transportation will have more applicable reasoning and results.\nI am still struggling with rendering to multiple formats. When i render, the html page has the other formats tab and it has the pdf linked but the pdf doesnt render correctly. I looked into it and found that having html specific syntax will not render to pdf so i tried something in the yaml to override that, but that did not work either."
  },
  {
    "objectID": "ResearchBlog.html#date-june-12th",
    "href": "ResearchBlog.html#date-june-12th",
    "title": "Daily Research Blog 2025",
    "section": "Date June 12th",
    "text": "Date June 12th\n\nI worked on finding the datasets I want to use for the lesson on public transport. It was a little difficult because a lot of the data is not complete for multiple years. I found one dataset that have information on public transportation usage from 2014-2024 but the variables are limited to ridership and mileage, not much useful information for analysis. However, I am going to include some sort of join portion in the lesson to join this data with census data in order to conduct a more useful analysis.\nContinue search for helpful data sets and begin writing the lesson on public transportation\nI am still trying to figure out what I want the exact structure of the lesson to be. I know i want to include a little mre nuances questions about the data and some more advanced data wrangling topics but I am not exactly sure how that is going to look. I think running a regression to create a model for ridership over time could be a more intermediate to advanced skill that would fit that data I have well but I also want the results of the analysis to be a little more interesting."
  },
  {
    "objectID": "ResearchBlog.html#date-june-13th",
    "href": "ResearchBlog.html#date-june-13th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 13th",
    "text": "Date: June 13th\n\nToday I worked on the lesson for Public Transportation. First, I narrowed down the initial data set to just CA public transit systems so that it is easier to work with. I made sure to include in the instructor manual how to filter initial data to be specific to your state so it is relevant to the students. The lesson starts off with an introduction to the variables and the dataset like before, but then instead of getting into questions about the data, first students will join census data from ca with information on race, income, unemp, and other socioeconomic factors to the transportation data for a more in depth analysis. I also created an initial basic example plotting the difference ca agencies and their total riders over time.\nI am going to start writing the parts of the lesson that require analysis in relation to socioeconomic factors. Hopefully I was be able to create a map plot to look at accessibility of public transit in different areas and compare this to the socioeconomic factors in that area. This will then guide further analysis on those relationships.\nI need to think through how to structure the activities using the spatial data so they are approachable for high school students. Some of the code is a little bit difficult to understand(such as facet and leaflet)"
  },
  {
    "objectID": "ResearchBlog.html#date-june-16th-2025",
    "href": "ResearchBlog.html#date-june-16th-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 16th 2025",
    "text": "Date: June 16th 2025\n\nToday i found another dataset that has California public transportation data with data about public transit stops. I did a lot of wrangling on this data set so i could combine it with the geography of the census tract. And then I cleaned a version of the tidycensus data and saved it as a csv. So now i have a dataset with transit data and geography(geoid as well) and a data set with census data and geography. Hopefully this will make for a good and simple enough lesson on joining and potential map visualizations.\nFinish the interactive tree lesson worksheet. I started work on it today and I just have to add the last problem. 3.In my transit data set, each stop has a value for the variable n_hours_in_service. A lot of stops have 0 for this value meaning they aren’t ever stopped at I assume? Should this be factored into calculations(because it says something about lack of stops) or would that make results look skewed. What other variables should I pull from tidycensus to allow for more in depth exploration. Because the data requires so much cleaning, i think it will be hard for this lesson to have students doing an individual project with their own dataset. That is why i want the original dataset they see in class to be comprehensive enough to have a different research question for all the students/groups in the class."
  },
  {
    "objectID": "ResearchBlog.html#date-june-17-2025",
    "href": "ResearchBlog.html#date-june-17-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 17 2025",
    "text": "Date: June 17 2025\n\nI worked on writing the qmd file for the students presentation. I basically just gave them space to make a 4 slide presentation with the first slide being their research question and data, the second being their wrangling process, the third being their ggplot code and plot, and the 4th is their insights and the trends they notices from the plot. I gave a quick instruction slide that i noted should be deleted before they render. I wanted to make the presentations pretty short and uniform so its east to get through if we have a shorter day. I then worked with the mathlink cubes for a while, taking pictures of all of the different data wrangling processes and the solutions for the questions used in the tree lecture. I also wrote instructions and took pictures that explain how to put the cubes together in a data like structure thats easy for students to take a part. Finally, I did a little more work on the public transit lesson, writing the next part of the lecture that involved joining the census data with the spatial transit data.\nI will use the mathlink cubes to represent and teach the process of joining since this goes right at the spot of the lecture i am currently writing.\nI’m not exactly sure if i am representing group_by and summarize correctly with the mathlink cubes. The example in the article is kind of confusing and I’m not really understanding what they are summarizing. I did group_by a certain color, and then organized that colors column by each shape in the column, but then when i summarise, im not sure if I should leave the rows where a shape repeats or if those would get filtered out with the group_by."
  },
  {
    "objectID": "ResearchBlog.html#date-june-19-2025",
    "href": "ResearchBlog.html#date-june-19-2025",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 19 2025",
    "text": "Date: June 19 2025\n\nI worked on updating some of the information in 5.2. I added a few more photo examples on how to upload and being working in a .qmd file. I also added how to render your work and then save or send the pdf to yourself to turn in on gradescope. I also worked on the Hooke’s law activity pdf, adding a place for the students to input the data from their lab. I also began work on the presentation for tommorows pizza and progress. I talk a little bit about what we have done with the website and our plans for how it is going to be used.\nI need to finish the presentation for tomorrow but i’m not exactly sure what else to include. I may talk about the work we have done with Hookes law and how we expect it to be implemented starting with PAYS on Monday.\nI am a little confused on what exactly the Hooke_activity.pdf is supposed to look like. I know we want it to be an example for the students to se what their work should look like when they turn it in, but im not exactly sure how to do that without giving them the answers to some of the code. I think we would probably want them to see that their plot should show up underneath their code chunk, but I cant do that without actually filling in the ggplot code. I didnt want to just input meaningless variables either because i thought that would get pretty confusing."
  },
  {
    "objectID": "ResearchBlog.html#date-june-23th",
    "href": "ResearchBlog.html#date-june-23th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 23th",
    "text": "Date: June 23th\n\nI finished all the in class materials for week 1 and week 2. I did a little bit more work on the planetary orbits lab though i think we may go over it and change some of the material.\nFinish editing planetary orbits and move onto the next 2 weeks of in class problems.\nI have a few questions today. First, Should all of the homework questions for week 1 be integrated into one singular .qmd file that way students dont have to keep downloading materials and everything can be kept. little more put together. I also wondered, however, if the in class assignments even needed to be rendered to pdf because they already have the instructions printed and i dont think they will be turning in a pdf version of their in class work."
  },
  {
    "objectID": "ResearchBlog.html#date-june-24th",
    "href": "ResearchBlog.html#date-june-24th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 24th",
    "text": "Date: June 24th\n\nToday I sat in with the Pays class and helped out with the Hooke’s Lab activity. There was definitely a lot of confusion, as we expected, but i think a lot of the students started to get a hang of things by the end of class. I also stopped my the TA session to make sure everyone had the lab assignment turned in correctly. I notices a lot of the students didnt go through the assignment in order? Some skipped to the r chunks and others tried to skip to the end to see what questions they had to answer. I saw this caused a lot of confusion with the work flow of the code chunks within the questions. I stated writing the extra lesson for next Wednesdays class with the olympic dataset and i made sure to emphasize the importance of following along with the lesson chronologically.\nFinish working on the olympics lesson. I also will sit in for the Pays class tomorrow to help them get started on the area of stars lab.\nAs of right now, i’m just writing wednesdays work how I would write any of the other in-class problems in a qmd file with instructions. But im wondering if it would be beneficial to have slides or some other presentation material for prof yassine. Today, there was little presentation in class an the students mostly just started work in groups right away and occasionally prof yassine would jump in to give tips so im not exactly sure if it works with his teaching style but i could definitely offer if he would like something like that."
  },
  {
    "objectID": "ResearchBlog.html#date-june-25th",
    "href": "ResearchBlog.html#date-june-25th",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 25th",
    "text": "Date: June 25th\n\nI went to the Pays class again and worked with them through the area of stars lab. A lot of them got stuck on the calculation of the area and side length (trying to make it more precise than it needed to be) and didnt get to the rstudio work yet, so I am going to go back today to help everyone finish the lab.I also added a section to the Olympic lesson about observational units and updated the tidyverse code example. I started adding code scaffold for students to practice data wrangling.\nGo to the pays class and help instruct them through the rest of the area of stars lab. I also have only one more week to finish for the in class assignments so i want to work on maybe changing or updating some of those repetitive problems.\nIm not sure how to keep students on track when they are following along with the .qmd lesson. For example, if someone doesn’t understand mutate and they use it incorrectly or don’t use it at all i want a way for the lesson to somehow get them back on track. I don’t know if solutions for some of activities in the lesson would help because then they could confirm whatever they are doing is working. But i also dont know if hat will encourage just looking at the answers and not fully understanding."
  },
  {
    "objectID": "ResearchBlog.html#date-june-26",
    "href": "ResearchBlog.html#date-june-26",
    "title": "Daily Research Blog 2025",
    "section": "Date: June 26",
    "text": "Date: June 26\n\nI went to the PAYS class today and helped the groups finish up the area of stars labs. From my understanding, everyone was able to grasp the concept of mutate which was a key goal of the lab from the rstudio perspective. I finished the Olympic lesson and a document with the solutions. I also went to the PAYS TA session and talked with a student about a data science program that he participated in recently. He showed me some of the work that he did and we talked about the structure of the program and what he felt he got out of it. Overall, it was a really insightful conversation especially for continuing work on the Saturdata lesson and plans. Finally, i made some updates to the planetary orbits lab. I spoke with professor Yassine and we agreed it would be helpful to have checkpoints within the lab so that everyone could get on the same page and groups were not left behind. Some groups would get stuck on certain topics in the previous labs which made it difficult to finish everything on the second day and also hard to manage if groups were beginning the in-class problems when they finished the lab. With the checkpoints, hopefully professor Yassine can get everyone on the same page a few times within the class so nobody falls behind and everything can be completed on time.\nI am going to continue to do some work on the Public Transport Lesson for Saturdata because I have quite finished it.\nI didnt get a chance to look over the week four questions but i figure we may be able to go over some of the in-class questions in our meeting tomorrow and see if there are any that can be either combined or removed so we can free up a day in the last week to do some sort o data visualization competition which I think would be really fun for the students."
  },
  {
    "objectID": "ResearchBlog.html#date-monday-june-30th",
    "href": "ResearchBlog.html#date-monday-june-30th",
    "title": "Daily Research Blog 2025",
    "section": "Date: Monday June 30th",
    "text": "Date: Monday June 30th\n\nI finished updates on the rest of the in class labs. This included adding checkpoints and any missing scaffolding. I also updated some of the instructions to have cleaner layouts that were easier to read than large paragraphs. I started a little work on the data viz intructions guide.\nGo to Pays and help them through planetary orbits lab. Go over the Olympic lesson and make sure I can teach any of the material if necessary and try to predict some sport where I think students will struggle so I can be ready to help in class.\nIm not sure about how I want to structure the documents for the data viz competition. Im thinking of having a really short intructions manual that basically just outlines the project and gives the students a spot to brainstorm questions, and then having a .qmd file like the rest of the activities for them to follow along in and do the actual work. The only think is im not sure what structure the students will want for their project so Im not sure how much scaffolding I should give them or if it should be pretty minimal as to let them be creative with that. I still have to try some things out and see what might work the best. Also a comment, but the PAYS class will need planets.csv today for the lab. I will try to help them all import it, but prof. yassine will need to send on canvas."
  },
  {
    "objectID": "ResearchBlog.html#date-tuesday-july-1st",
    "href": "ResearchBlog.html#date-tuesday-july-1st",
    "title": "Daily Research Blog 2025",
    "section": "Date: Tuesday July 1st",
    "text": "Date: Tuesday July 1st\n\nI went to class and helped students work through the planetary orbits lab. A lot of students were having trouble with log transformations so after class I wrote up a guide to help students understand the concept of the log-log plot and posted t to canvas. I finished the instructions and interactive versions of the data viz activity. I also started working on an example project so students can look at a finished product. Hopefully this will help them get a sense of how much they should write and the kinds of questions they might want to ask\nfinish working on the example product for the data viz competition\nI don’t have many questions today. Maybe just wondering how we should go about instructing the olympic lesson and getting ready for the logistics of lass tomorrow with that being the main focus."
  },
  {
    "objectID": "ResearchBlog.html#date-wednesday-july-2nd",
    "href": "ResearchBlog.html#date-wednesday-july-2nd",
    "title": "Daily Research Blog 2025",
    "section": "Date: Wednesday July 2nd",
    "text": "Date: Wednesday July 2nd\n\nI went to both class and the ta study session to help students finish the planetary orbits lab. I worked on updating the public transit lesson in the ds4hs project. I also focused on taking screenshots and writing little captions or explanations to the images to I could start preparing for my final project. I talked with professor Yassine in class and he said it may be helpful for me to add some reflection questions here and there in the labs in order to get some more data for my final project so I added a few questions to the end of the Olympics lesson. I also thought I could add those same questions or similar questions to the end of the data viz activity that way we hve information from the beginning(hooke’s law), middle(Olympics), and end of the course(data viz).\nI am going to class to help instruct the olympic lesson. I think im going to tell students just to render and turn in their report no matter where they get to at the end of class and ill save the last 8 ish minutes so they can fill out the reflection questions. This way I can start looking at the difference between their responses from the first lab and now.\nAgain not really a question but we may have to remove the from the students qmd’s along with the use package fontawesome5 in the header. I think that pomonas rstudio server is not updated to have that package and none of their reports were rendering. I alsready removed it for the olympic lesson but we may need to resend to adam or I can just post directly to canvas."
  },
  {
    "objectID": "CoffeeRatings.html",
    "href": "CoffeeRatings.html",
    "title": "Coffee Ratings",
    "section": "",
    "text": "In this project I will be using data from Jo Hardin’s collection of “Tidy Tuesday” data sets.\n\nlibrary(tidyverse)\ndata &lt;- tidytuesdayR::tt_load('2020-07-07')\ncoffee_ratings &lt;- data[[\"coffee_ratings\"]]\n\nThe data Im using comes from the Coffee Quality Database posted by Buzzfeed Data Scientist James LeDoux. These data were collected from the Coffee Quality Institute’s review pages in January 2018.\n\ncoffee_ratings |&gt;\n  head(1)\n\n# A tibble: 1 × 43\n  total_cup_points species owner    country_of_origin farm_name lot_number mill \n             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;             &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;\n1             90.6 Arabica metad p… Ethiopia          metad plc &lt;NA&gt;       meta…\n# ℹ 36 more variables: ico_number &lt;chr&gt;, company &lt;chr&gt;, altitude &lt;chr&gt;,\n#   region &lt;chr&gt;, producer &lt;chr&gt;, number_of_bags &lt;dbl&gt;, bag_weight &lt;chr&gt;,\n#   in_country_partner &lt;chr&gt;, harvest_year &lt;chr&gt;, grading_date &lt;chr&gt;,\n#   owner_1 &lt;chr&gt;, variety &lt;chr&gt;, processing_method &lt;chr&gt;, aroma &lt;dbl&gt;,\n#   flavor &lt;dbl&gt;, aftertaste &lt;dbl&gt;, acidity &lt;dbl&gt;, body &lt;dbl&gt;, balance &lt;dbl&gt;,\n#   uniformity &lt;dbl&gt;, clean_cup &lt;dbl&gt;, sweetness &lt;dbl&gt;, cupper_points &lt;dbl&gt;,\n#   moisture &lt;dbl&gt;, category_one_defects &lt;dbl&gt;, quakers &lt;dbl&gt;, color &lt;chr&gt;, …\n\n\nThe variable I am using is ‘total_cup_points’ which is the Total rating/points of a specific coffee on a scale from 0-100.\n\nnew_coffee_ratings &lt;- coffee_ratings |&gt;\n  group_by(country_of_origin) |&gt;\n  filter(!is.na(country_of_origin)) |&gt;\n  summarise(avg_score = mean(total_cup_points, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_score))\n\nThis chunk takes the average “total_cup_points” for each country in the data set, and arranges those values in descending order. Now we can plot our findings using ggplot.\n\nggplot(new_coffee_ratings, aes(x = reorder(country_of_origin, avg_score), y = avg_score, fill = country_of_origin)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = 'Average \"Cup Points\" Score by Country of Origin',\n       x = \"Country of Origin\",\n       y = \"Average Score\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text = element_text(size = 7))\n\n\n\n\n\n\n\n\nAs we can see from the plot, Papa New Guinea has the highest Average Score in total cup points. We can also conclude that most total cup point scores are between 75 and 90, as all of the bars are relatively close in length."
  },
  {
    "objectID": "SimulatedSpotify.html#generate-listening-history",
    "href": "SimulatedSpotify.html#generate-listening-history",
    "title": "Simulated Spotify Wrapped",
    "section": "Generate Listening History",
    "text": "Generate Listening History\n\nwant to simulate a YEAR worth of listening history\n60,000 / 3.5 = 17,100\n\n\nmy_spotify_library &lt;- read.csv(\"~/paitynleigh.github.io/MyspotifyLibrary.csv\")\n\ncolnames(my_spotify_library)\n\n[1] \"Track.name\"    \"Artist.name\"   \"Album\"         \"Playlist.name\"\n[5] \"Type\"          \"ISRC\"          \"Spotify...id\" \n\n\n\n\nTool “Tune My Music” Used to collect playlist data https://www.tunemymusic.com/transfer"
  },
  {
    "objectID": "SimulatedSpotify.html#data-conclusions",
    "href": "SimulatedSpotify.html#data-conclusions",
    "title": "Simulated Spotify Wrapped",
    "section": "Data Conclusions",
    "text": "Data Conclusions\n\nRecreating Spotify Wrapped\nTop 5 Songs, Artists, and Albums\n\n\ntop_5 &lt;- function(data, colname){\n  data |&gt;\n    count({{colname}}, sort = TRUE)|&gt;\n    head(5)\n}\n\n\nCan use this same function for songs, artists, and albums"
  },
  {
    "objectID": "SimulatedSpotify.html#now-lets-see-1-iteration-of-simulated-listening-history",
    "href": "SimulatedSpotify.html#now-lets-see-1-iteration-of-simulated-listening-history",
    "title": "Simulated Spotify Wrapped",
    "section": "Now, Lets see 1 iteration of Simulated Listening History",
    "text": "Now, Lets see 1 iteration of Simulated Listening History\n\nfind_top_5 &lt;- function(simulated_year) {\n  top_songs &lt;- top_5(simulated_year, Track.name)\n  top_artists &lt;- top_5(simulated_year, Artist.name)\n  top_albums &lt;- top_5(simulated_year, Album)\n  \n  # labels each table \n  list(songs = top_songs, artists = top_artists, albums = top_albums)\n}\nfind_top_5(simulated_year(my_spotify_library))\n\n$songs\n   Track.name  n\n1      Nobody 41\n2   Die Young 35\n3 Lay Me Down 32\n4      Harvey 26\n5        Hope 26\n\n$artists\n          Artist.name   n\n1              Mitski 473\n2        Lana Del Rey 243\n3      Arctic Monkeys 221\n4 Panic! At The Disco 208\n5    Childish Gambino 204\n\n$albums\n                      Album   n\n1 Cry Baby (Deluxe Edition) 125\n2             Be the Cowboy  92\n3                Apollo XXI  86\n4       Death of a Bachelor  85\n5                 Puberty 2  85"
  },
  {
    "objectID": "SimulatedSpotify.html#mapping",
    "href": "SimulatedSpotify.html#mapping",
    "title": "Simulated Spotify Wrapped",
    "section": "Mapping",
    "text": "Mapping\n\nLets create multiple simulated years of listening\n\n\niters &lt;- 1000\n\nresults &lt;- map(1:iters, ~ {\n  simulated_year &lt;- simulated_year(my_spotify_library) \n  find_top_5(simulated_year) \n})\n\n\nWhat questions can mapping help us answer?"
  },
  {
    "objectID": "SimulatedSpotify.html#probability",
    "href": "SimulatedSpotify.html#probability",
    "title": "Simulated Spotify Wrapped",
    "section": "Probability",
    "text": "Probability\n\nHow likely is it that a specific artist will be in my top 5? Top 1??\n\n\ncheck_artist &lt;- function(top_artists, artist) {\n  in_top_5 &lt;- top_artists|&gt;\n    filter(Artist.name == artist) |&gt;\n    # Will return Boolean for this statement\n    nrow() &gt; 0  \n  \n  is_top_artist &lt;- top_artists |&gt;\n    pull(Artist.name) |&gt;\n    head(1) == artist \n  \n  list(\n    in_top_5 = in_top_5,\n    is_top_artist = is_top_artist\n  )\n}"
  },
  {
    "objectID": "SimulatedSpotify.html#cont.",
    "href": "SimulatedSpotify.html#cont.",
    "title": "Simulated Spotify Wrapped",
    "section": "cont.",
    "text": "cont.\n\nartist &lt;- \"TV Girl\"\n\nartist_occurrences &lt;- map(results, function(results) {\n\n  check_artist(pluck(results, \"artists\"), artist)\n})\n\ndata &lt;- map_dfr(artist_occurrences, ~ tibble(\n  in_top_5 = pluck(.x, \"in_top_5\"),\n  is_top_artist = pluck(.x, \"is_top_artist\")\n))\n\ndata|&gt;\n  head(1)\n\n# A tibble: 1 × 2\n  in_top_5 is_top_artist\n  &lt;lgl&gt;    &lt;lgl&gt;        \n1 FALSE    FALSE"
  },
  {
    "objectID": "SimulatedSpotify.html#conclusions",
    "href": "SimulatedSpotify.html#conclusions",
    "title": "Simulated Spotify Wrapped",
    "section": "Conclusions",
    "text": "Conclusions\n\nprob_top_5 &lt;- data |&gt;\n  select(in_top_5) |&gt;\n  summarise(mean = mean(in_top_5))|&gt;\n  pull(mean)\n\nprob_top_1 &lt;- data |&gt;\n  select(is_top_artist) |&gt;\n  summarise(mean = mean(is_top_artist))|&gt;\n  pull(mean)\n\nprob_top_5\n\n[1] 0.331\n\nprob_top_1\n\n[1] 0"
  },
  {
    "objectID": "Rodentdata.html",
    "href": "Rodentdata.html",
    "title": "Rodent Species",
    "section": "",
    "text": "In this project I will be using data from Jo Hardin’s collection of “Tidy Tuesday” data sets.\n\ndata &lt;- tidytuesdayR::tt_load('2023-05-02')\nspecies &lt;- data[[\"species\"]]\nlibrary(tidyverse)\n\nThe data I am using comes from the Portal Project.The Portal Project is a long-term ecological study being conducted near Portal, AZ. Since 1977, the site has been used to study the interactions among rodents, ants and plants and their respective responses to climate. This data pertains specifically to rodents.\n\nspecies |&gt;\n  head(1)\n\n# A tibble: 1 × 15\n  species scientificname  taxa   commonname     censustarget unidentified rodent\n  &lt;chr&gt;   &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 BA      Baiomys taylori Rodent Northern pygm…            1            0      1\n# ℹ 8 more variables: granivore &lt;dbl&gt;, minhfl &lt;dbl&gt;, meanhfl &lt;dbl&gt;,\n#   maxhfl &lt;dbl&gt;, minwgt &lt;dbl&gt;, meanwgt &lt;dbl&gt;, maxwgt &lt;dbl&gt;, juvwgt &lt;dbl&gt;\n\n\nThe variables I will be using are ‘meanwgt’ and ‘juvwgt’. These are the average adult weight and the average juvenile weight of a given species, respectively.\n\nweight_data &lt;- species |&gt;\n  mutate(weight_difference = meanwgt - juvwgt) |&gt;\n  filter(!is.na(weight_difference)) |&gt;\n  select(commonname, weight_difference)\n\nI wanted to find the average amount of growth a given rodent experiences in its lifetime so I subtracted the juvenile weight from the mean weight of the species. We then get a table with the species’ common name and the “weight_difference” or the growth amount in the species life.\n\nlibrary(ggplot2)\nggplot(weight_data, aes(x = reorder(commonname, weight_difference), y = weight_difference, fill = weight_difference)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + \n  scale_fill_gradient(low = \"pink\", high = \"orange\") +\n  labs(title = \"Average Lifetime Growth Across Rodent Species\",\n       x = \"Species Name\",\n       y = \"Growth Amount (g)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can conclude from the visual that the White-throated Woodrat experiences the largest amount of growth in its life. The growth amount measurement does not account for the size of the species meaning a better measurement for comparison would be the growth amount relative to the species average size."
  },
  {
    "objectID": "Project3.html",
    "href": "Project3.html",
    "title": "Poker Hands Probability",
    "section": "",
    "text": "In this project I plan to simulate the probability of being dealt a specific hand while playing poker. First I will simulate a deck of cards and then simulate the drawing of a 5 card hand with a function. Then I will use another function to check if the hand drawn at random matches a specific, special hand such as a full house, royal flush, etc.\nFirst, lets simulate a deck of cards\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(purrr)\n\n#use crossing function to associate each of the values with one of each of the suits \n\n\ndeck &lt;- crossing(value = c(2:10, \"J\", \"Q\", \"K\", \"A\"),\n\n                 suit = c(\"Spades\", \"Diamonds\", \"Clubs\", \"Hearts\"))\n\nNow, lets create a function that will deal a random hand of 5 cards from the deck.\n\ndeal_hand &lt;- function(deck){\n\n#pick random row numbers then index through deck data set to pick those specific rows \n\n  hand &lt;- deck[sample(nrow(deck), 5, replace = FALSE), ]\n\n  return(hand)\n\n}\n\ndeal_hand(deck)\n\n# A tibble: 5 × 2\n  value suit    \n  &lt;chr&gt; &lt;chr&gt;   \n1 K     Diamonds\n2 A     Clubs   \n3 3     Clubs   \n4 5     Clubs   \n5 J     Diamonds\n\n\nNow, lets write a few functions that will check for special hands.\n\ncheck_straight &lt;- function(hand){\n\n  value_order &lt;- c(\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"J\", \"Q\", \"K\", \n\n\"A\")\n\n  ordered_hand_values &lt;- match(hand$value, value_order)\n  \n  is_straight &lt;- all(diff(sort(ordered_hand_values)) == 1)\n\n  return(is_straight)\n\n}\n\ncheck_royal_flush &lt;- function(hand){\n\n  royal_values &lt;- c(\"10\", \"J\", \"Q\", \"K\", \"A\")\n\n  \n\n  is_flush &lt;- if_else(length(unique(hand$suit)) == 1, TRUE, FALSE)\n\n  is_royal &lt;- if_else(all(royal_values %in% hand$value), TRUE, FALSE)\n\n  return(is_flush && is_royal)\n\n}\n\ncheck_full_house &lt;- function(hand){\n\n  value_frequency &lt;- table(hand$value)\n\n  \n\n  #Gives True if there exactly 2 unique values and there are 3 repeats of the first value and 2 repeats of the second\n\n    if_else(length(value_frequency) == 2 &\n\n            all(value_frequency == c(3,2)), TRUE, FALSE)\n\n}\n\nNow, say this is a specific night at a casino and we want to know the probability that someone will be dealt a full house or a royal flush. Lets map these functions over numerous iterations in order to model this.\n\nset.seed(738)\niterations &lt;- 100000\n\nresults &lt;- \n  tibble(full_house = mean(map_lgl(1:iterations, ~check_full_house(deal_hand(deck)))),\n        royal_flush = mean(map_lgl(1:iterations, ~check_royal_flush(deal_hand(deck)))),\n        straight = mean(map_lgl(1:iterations, ~check_straight(deal_hand(deck)))))\n\nresults &lt;- results|&gt;\n  pivot_longer(cols = everything(), names_to = \"hand\", values_to = \"probability\")\n\nNow lets plot these results using a bar plot.\n\nggplot(results, aes(x = hand, y = probability, fill = hand)) +\n\n  geom_bar(stat = \"identity\") +\n\n  labs(title = \"Probabilities of Different Poker Hands\",\n\n       x = \"Poker Hand\",\n\n       y = \"Probability\") +\n\n  theme_minimal()\n\n\n\n\n\n\n\n\nAs we can see on the bar plot, a straight is the most common out of all the hands followed a full house and then a royal flush. With this information we can start to understand how common it is to be dealt certain hands in poker. This can be useful when trying to curb cheating attempts and or trying to place bets. This could also be helpful when designing online poker games and attempting to accurately replicate a real life game."
  },
  {
    "objectID": "WAIDatabaseStudy.html",
    "href": "WAIDatabaseStudy.html",
    "title": "WAI Database Study",
    "section": "",
    "text": "library(RMariaDB)\nlibrary(tidyverse)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\nIn this project I plan to use the data from the Wideband Acoustic Immittance (WAI) Database hosted by Smith College. I plan to replicate a figure published in the Official Journal of the American Auditory Society by Susan Voss titled “Mean Absorbance from each Publication in the WAI Database” Voss(2020). The database contains 3 data sets: Measurements, PI_Info, and Subjects, which all have different information pertaining to the study.\nHere is the measurements table,\n\nDESCRIBE Measurements\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSession\nint\nNO\nPRI\nNA\n\n\n\nEar\nvarchar(50)\nNO\nPRI\n\n\n\n\nInstrument\nvarchar(50)\nNO\nPRI\n\n\n\n\nAge\nfloat\nYES\n\nNA\n\n\n\nAgeCategory\nvarchar(50)\nYES\n\nNA\n\n\n\nEarStatus\nvarchar(50)\nYES\n\nNA\n\n\n\nTPP\nfloat\nYES\n\nNA\n\n\n\nAreaCanal\nfloat\nYES\n\nNA\n\n\n\n\n\n\nHere is the PI_Info table,\n\nDESCRIBE PI_Info\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nYear\nint\nNO\n\nNA\n\n\n\nAuthors\ntext\nNO\n\nNA\n\n\n\nAuthorsShortList\ntext\nNO\n\nNA\n\n\n\nTitle\ntext\nNO\n\nNA\n\n\n\nJournal\ntext\nNO\n\nNA\n\n\n\nURL\ntext\nNO\n\nNA\n\n\n\nAbstract\ntext\nNO\n\nNA\n\n\n\nDataSubmitterName\ntext\nNO\n\nNA\n\n\n\nDataSubmitterEmail\ntext\nNO\n\nNA\n\n\n\n\n\n\nAnd here is the Subjects table,\n\nDESCRIBE Subjects\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nIdentifier\nvarchar(50)\nNO\nPRI\nNA\n\n\n\nSubjectNumber\nint\nNO\nPRI\nNA\n\n\n\nSessionTotal\nint\nNO\n\nNA\n\n\n\nAgeFirstMeasurement\nfloat\nYES\n\nNA\n\n\n\nAgeCategoryFirstMeasurement\nvarchar(50)\nYES\n\nNA\n\n\n\nSex\nvarchar(50)\nNO\n\nNA\n\n\n\nRace\nvarchar(50)\nNO\n\nNA\n\n\n\nEthnicity\nvarchar(50)\nNO\n\nNA\n\n\n\nLeftEarStatusFirstMeasurement\nvarchar(50)\nNO\n\nNA\n\n\n\nRightEarStatusFirstMeasurement\nvarchar(50)\nNO\n\nNA\n\n\n\n\n\n\nI started of by arranging the data using a SQL query.\n\n    SELECT \n        m.Frequency,\n        m.Identifier,\n        m.Instrument,\n        AVG(m.Absorbance) AS Mean_Absorption, \n        CONCAT(pi.AuthorsShortList, ' (', pi.Year, ')', ' N=', COUNT(DISTINCT CONCAT(m.SubjectNumber, '-', m.Ear)),'; ', m.Instrument) AS Label\n    FROM \n        Measurements m\n    JOIN \n        PI_Info pi\n        ON m.Identifier = pi.Identifier\n    WHERE \n        m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', 'Lewis_2015', 'Lui_2008', 'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', 'Voss_1994', 'Voss_2010', 'Werner_2010') \n        AND m.Frequency BETWEEN 200 AND 8000\n    GROUP BY \n        m.Frequency, \n        m.Identifier, \n        m.Instrument\n    ORDER BY \n        m.Frequency, \n        m.Identifier, \n        m.Instrument\n\nIn this query, I grouped the data by Frequency, Identifier, and Instrument. In order to get the variable “AuthorShortList” I joined the PI_Info table and the Measurements table on SubjectNumber. I used Concat to make a label for each of the studies with the number of unique ears, the instrument used, and the year and author of the study. My goal was to match the figure created by Voss in 2022, so I filtered for only studies included in that specific plot.\n\nlibrary(ggplot2)\n\n\nggplot(new_table, aes(x = Frequency, y = Mean_Absorption, color = Label)) +\n  geom_line(size = .7, na.rm = TRUE) +  \n  scale_x_log10(name = \"Frequency (Hz)\",\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    labels = c(\"200\", \"400\", \"600\", \"800\", \"1000\", \"2000\", \"4000\", \"6000\", \"8000\")) +\n  scale_y_continuous(\n    name = \"Mean Absorbance\",\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1)  \n  ) +\n  labs(\n    title = \"Mean Absorbance From Each Publication in the WAI Database\",  \n    color = NULL \n  ) +\n  theme_minimal() + \n  theme(\n    axis.text = element_text(size = 5),\n    axis.title = element_text(size = 7),\n    plot.title = element_text(size = 9, face = \"bold\", hjust = .5),\n    legend.text = element_text(size = 5),\n    legend.position = c(0.28, 0.9),\n    legend.key.size = unit(0.1, \"cm\"),\n    legend.spacing = unit(0.01, \"cm\"),\n    legend.background = element_rect(color = \"black\", size = .2, fill = \"white\"),\n    aspect.ratio = 1\n  ) \n\n\n\n\n\n\n\n\nThis table shows the mean absorbance of frequencies ranging from 200 HZ to 8000 HZ in 12 different studies in the WAI database. As seen in the table, absorbance, on average, increases as frequency increases up until around 1000 HZ, when it drops off and begins to decrease again.\n\nSELECT \n    m.Frequency, \n    s.Sex, \n    AVG(m.Absorbance) AS Avg_Absorbance\nFROM \n    Measurements m\nJOIN \n    Subjects s\nON \n    m.SubjectNumber = s.SubjectNumber\nWHERE \n    m.Identifier = 'Aithal_2015'\n    AND s.Sex != 'Unknown'\n    AND m.Frequency BETWEEN 200 AND 8000\nGROUP BY \n    m.Frequency, s.Sex\nORDER BY \n    m.Frequency, s.Sex;\n\nNow with this SQL query, I am doing a similar thing to the last, except now I am also grouping by “sex” which required me to join the table “Subjects” also in the WAI database. For this table i chose to focus on 1 study in the WAI data base, this being A Comparison With High-Frequency Tympanometry, Automated Brainstem Response, and Transient Evoked and Distortion Product Otoacoustic Emissions(Aithal 2015).\n\ndbDisconnect(con_wai, shutdown = TRUE)\n\n\nlibrary(ggplot2)\n\nggplot(new_table4, aes(x = Frequency, y = Avg_Absorbance, color = Sex)) +\n  geom_line(size = 0.7, na.rm = TRUE) +\n  scale_x_log10(name = \"Frequency (Hz)\",\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    labels = c(\"200\", \"400\", \"600\", \"800\", \"1000\", \"2000\", \"4000\", \"6000\", \"8000\")) +\n  scale_y_continuous(\n    name = \"Average Absorbance\",\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1)\n  ) +\n  labs(\n    title = \"Average Absorbance by Frequency and Gender(Aithal 2015)\",\n    color = NULL \n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_text(size = 8),\n    axis.title = element_text(size = 12),\n    plot.title = element_text(size = 16, face = \"bold\"),\n    legend.text = element_text(size = 8),\n    legend.position = c(0.1, 0.9),\n    legend.box.background = element_rect(color = \"black\", fill = \"white\", size = 0.5) \n  ) +\n  coord_cartesian(xlim = c(200, 8000)) \n\n\n\n\n\n\n\n\nAgain, this plot shows the average absorbance over frequencies ranging from 200 to 8000. The 2 lines in the plot represent Male and Female tested subjects. As shown by the plot, there is almost no difference in the mean absorbance rates based on gender."
  }
]